{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.19.5 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.19.5 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py==2.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from h5py==2.10.0) (1.19.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py==2.10.0) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py==2.10.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==3.6.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from gensim==3.6.0) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim==3.6.0) (1.5.2)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from gensim==3.6.0) (5.0.0)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim==3.6.0) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.6.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4035,
     "status": "ok",
     "timestamp": 1620716501332,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "wxRqFag-N8dW",
    "outputId": "b5211c30-c91c-472d-f826-057ad5c61271",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepcut in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (0.7.0.0)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from deepcut) (2.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from deepcut) (1.19.5)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from deepcut) (1.1.3)\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from deepcut) (2.4.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from deepcut) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from deepcut) (0.23.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py->deepcut) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->deepcut) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->deepcut) (2.8.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (3.16.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (0.3.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (0.35.1)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (2.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (0.12.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (1.12)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (1.32.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->deepcut) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->deepcut) (0.17.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (1.30.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (50.3.1.post20201107)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (2020.6.20)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepcut --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5877,
     "status": "ok",
     "timestamp": 1620716503182,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "rHO_3T9BOGui",
    "outputId": "1a44454f-1da2-4648-cdbb-c18110a79609",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pythainlp in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (2.3.1)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from pythainlp) (0.9.7)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pythainlp) (2.24.0)\n",
      "Requirement already satisfied: tinydb>=3.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from pythainlp) (4.4.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pythainlp) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pythainlp) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.22.0->pythainlp) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install pythainlp --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask_ngrok in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (0.0.25)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from flask_ngrok) (2.24.0)\n",
      "Requirement already satisfied: Flask>=0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask_ngrok) (1.1.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->flask_ngrok) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->flask_ngrok) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->flask_ngrok) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->flask_ngrok) (2020.6.20)\n",
      "Requirement already satisfied: click>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask_ngrok) (2.11.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=0.8->flask_ngrok) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask_ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "G9D118ZAOZZB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NATTHAWATTUNGRUETHAI\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# MaLSTM import\n",
    "import deepcut\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import difflib\n",
    "\n",
    "# Question import\n",
    "import requests\n",
    "\n",
    "# Category model import\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, jsonify, request\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaLSTM Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5qw6hsPwOmcD"
   },
   "outputs": [],
   "source": [
    "#Clean Text\n",
    "def remove_repettition(text):\n",
    "    token_list = list(text)\n",
    "    if len(token_list) > 2:\n",
    "        filter_list = [True, True]\n",
    "        n = len(token_list)\n",
    "        for i in range(2, n):\n",
    "            if (token_list[i] == token_list[i-1]) and (token_list[i] == token_list[i-2]):\n",
    "                filter_list.append(False)\n",
    "            else:\n",
    "                filter_list.append(True)\n",
    "\n",
    "        output = ''.join(np.array(token_list)[filter_list])\n",
    "    else:\n",
    "        output = text\n",
    "    return output\n",
    "\n",
    "def cleansing(text):\n",
    "    # \\t, \\n, \\xa0 and other special characters. Replace by blank string\n",
    "    text = re.sub('[\\t\\n\\xa0\\\"\\'!?\\/\\(\\)%\\:\\=\\-\\+\\*\\_ๆ]', '', text)\n",
    "    \n",
    "    # Numbers. Replace by space\n",
    "    text = re.sub('[0-9]', ' ', text)\n",
    "    \n",
    "    # Dot. Replace by space\n",
    "    text = re.sub('[\\.]', ' ', text)\n",
    "    \n",
    "    # One or more consecutive space. Replace by single space\n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    \n",
    "    # Remove 2 or more repettition\n",
    "    text = remove_repettition(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NNqVro6LPo8a"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "wv_model = gensim.models.Word2Vec.load('corpus.th.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6cfjBM4tP4UK"
   },
   "outputs": [],
   "source": [
    "def word2idx(word):\n",
    "    index = 0\n",
    "    index = wv_model.wv.vocab[word].index\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oIAJw0p7P7XZ"
   },
   "outputs": [],
   "source": [
    "def word_index(listword):\n",
    "    dataset = []\n",
    "    vocabulary = dict()\n",
    "    inverse_vocabulary = ['<unk>']  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
    "    for sentence in listword:\n",
    "        tmp = []\n",
    "        for w in sentence:\n",
    "            if w not in wv_model:\n",
    "                continue\n",
    "\n",
    "            if w not in vocabulary:\n",
    "                vocabulary[w] = len(inverse_vocabulary)\n",
    "                tmp.append(len(inverse_vocabulary))\n",
    "                inverse_vocabulary.append(w)\n",
    "            else:\n",
    "                tmp.append(word2idx(w))\n",
    "        dataset.append(tmp)\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LO-WyseOP-li"
   },
   "outputs": [],
   "source": [
    "# define word embedding\n",
    "vocab_list = [(k, wv_model.wv[k]) for k, v in wv_model.wv.vocab.items()]\n",
    "embeddings_matrix = np.zeros((len(wv_model.wv.vocab.items()) + 1, wv_model.vector_size))\n",
    "for i in range(len(vocab_list)):\n",
    "    word = vocab_list[i][0]\n",
    "    embeddings_matrix[i + 1] = vocab_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1LVdY7-KDCP9EF2jZebOawVR_3jUQnSGM"
    },
    "executionInfo": {
     "elapsed": 6358,
     "status": "ok",
     "timestamp": 1620716838058,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "YzIv6bWzQC-a",
    "outputId": "14f29683-2dc8-45ec-f731-2f7f617dc726"
   },
   "outputs": [],
   "source": [
    "# vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XdooUj6QQITq"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "embeddings_matrix = 1 * np.random.randn(len(vocab_list) + 1, EMBEDDING_DIM)  # This will be the embedding matrix\n",
    "embeddings_matrix[0] = 0  # So that the padding will be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0FdjJe_VPdZ0"
   },
   "outputs": [],
   "source": [
    "# Model variables\n",
    "n_hidden = 256\n",
    "batch_size = 128\n",
    "n_epoch = 100\n",
    "max_seq_length = 2704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1620716858559,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "eqK0ymH9QKRy",
    "outputId": "31ac3c38-d119-42ac-f01c-2d5c3a8a06fe"
   },
   "outputs": [],
   "source": [
    "# embeddings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "an1uk86LQTio"
   },
   "outputs": [],
   "source": [
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JgPsQ8MlPfWA"
   },
   "outputs": [],
   "source": [
    "# The visible layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(embeddings_matrix), EMBEDDING_DIM, weights=[embeddings_matrix], input_length=max_seq_length, trainable=False)\n",
    "\n",
    "# Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# Since this is a siamese network, both sides share the same LSTM\n",
    "shared_lstm = LSTM(n_hidden)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "# Calculates the distance as defined by the MaLSTM model\n",
    "malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "# Pack it all up into a model\n",
    "malstm = Model([left_input, right_input], [malstm_distance])\n",
    "\n",
    "\n",
    "malstm.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Start training\n",
    "training_start_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1620717012710,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "Nh9milBGQpYY",
    "outputId": "6383054e-67f5-410f-8332-50281e0c54f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2704)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2704)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 2704, 300)    9468300     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          570368      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "==================================================================================================\n",
      "Total params: 10,038,668\n",
      "Trainable params: 570,368\n",
      "Non-trainable params: 9,468,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "malstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JUOlaUM6OylG"
   },
   "outputs": [],
   "source": [
    "# Load best weight from model\n",
    "malstm.load_weights('sm_colab_ka.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y69P6GtuXAaB"
   },
   "source": [
    "#Test with Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Kjaib296O0US"
   },
   "outputs": [],
   "source": [
    "def prepare_for_predict(input_questions):\n",
    "    q_input= []\n",
    "    cleansing(input_questions)\n",
    "    tokenized_input_1 =deepcut.tokenize(input_questions)\n",
    "    for sentence in tokenized_input_1:\n",
    "      q_input.append(sentence)\n",
    "    q_input= word_index(tokenized_input_1)\n",
    "    q_input = pad_sequences(q_input, maxlen=max_seq_length)\n",
    "    return q_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CGdqwM2qWt0r"
   },
   "outputs": [],
   "source": [
    "max_word = 19219\n",
    "max_seq_length = 2704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pL8GEUFCWEKq"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def tokenize_text_list(ls):\n",
    "    \"\"\"Tokenize list of text\"\"\"\n",
    "    return list(chain.from_iterable([deepcut.tokenize(ls)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicate list\n",
    "def duplicate(testList, n):\n",
    "    return [ele for ele in testList for _ in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies = {'user': 'j%3A%7B%22id%22%3A%22root-id%22%2C%22username%22%3A%22root%22%2C%22role%22%3A%22root%22%7D',\n",
    "          'authorization':'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6InJvb3QtaWQiLCJuYW1lIjoicm9vdGFkbWluIiwidXNlcm5hbWUiOiJyb290Iiwicm9sZSI6InJvb3QiLCJpYXQiOjE2MjA3NTUxMzIsImV4cCI6MTYyMDc5ODMzMn0.-uNCuzyIYxA-4cTWPYlM_hyTfFXZhsgVeoa6Xis3POg'}\n",
    "url = 'https://natthawat.live/api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('%s/km/faq' % url, cookies=cookies)\n",
    "faqs = json.loads(response.text)\n",
    "\n",
    "response = requests.get('%s/km/category' % url, cookies=cookies)\n",
    "categories = json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_data = {}\n",
    "for category in categories:\n",
    "    questions_data[category['category']] = []\n",
    "    for faq in faqs:\n",
    "        if faq['category']['category'] == category['category']:\n",
    "            questions_data[category['category']].append(faq['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'หลักสูตร': ['วิชาภาคบังคับที่มีวิชาต่อเนื่อง มีอะไรบ้าง หลักสูตรปกติ?',\n",
       "  'ถ้าไม่ได้เป็นนักศึกษาชั้นปีที่ 3 สามารถฝึกงานได้หรือไม่？',\n",
       "  'วิชา CPE223/Digital มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิชา CPE332/Professional issuesมีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 2 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 4 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวะคอมหลักสูตรวิทยาศาตร์ข้อมูลสุขภาพมีอัตราค่าเรียนเท่าไหร่',\n",
       "  'วิชา CPE100/Programming มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิชา CPE343/Object orientedมีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิชา CPE375/Interactive computingมีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 3 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 1 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ ปีที่1-2 เรียนอะไรบ้าง?',\n",
       "  'ถ้าต้องการฝึกงานต้องทำอย่างไรบ้าง?',\n",
       "  'วิชา CPE224/Computer architectures มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิชาภาคบังคับที่มีวิชาต่อเนื่อง  หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nมีอะไรบ้าง ?',\n",
       "  'ถ้าต้องการทำ Work Integrate Leaning หรือ Wil ต้องทำอย่างไร?',\n",
       "  'วิชาเลือกที่มีวิชาบังคับลงก่อน หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ ?',\n",
       "  'วิชา CPE329/Business intelligence มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิชา CPE342/Java programmingมีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิชา CPE111/Data Structure มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิชา CPE231/Database มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิศวะคอม/หลักสูตรปกติ ปี 1 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิชา CPE212/Algorithm มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิศวะคอม/หลักสูตรปกติ ปี 2 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรเรสิเดนทอล คอเลจ ปีที่ 3-4 เรียนอะไรบ้าง?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ ปีที่ 4 เรียนอะไรบ้าง?',\n",
       "  'วิชาเลือกเสรีต้องลงวิชานอกภาคเท่านั้นหรือไม่?',\n",
       "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 2 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิชา CPE325/Big data มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 4 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 2 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 3 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรนานาชาติปี 1 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 1 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'ฝึกงานจำเป็นต้องครบ40ชั่วโมงไหม？',\n",
       "  'วิศวะคอม/หลักสูตรนานาชาติปี 4 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวะคอม/ มีทั้งหมดกี่หลักสูตร? มีหลักสูตรอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรปกติ  ปี 4 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิชาเลือกที่มีวิชาบังคับลงก่อน หลักสูตรปกติ?',\n",
       "  'วิชา CPE213/Data model วิชาตัวต่อมั้ยครับ?',\n",
       "  'วิศวะคอม/หลักสูตรปกติ  ปี 4 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิชา CPE121/Discrete มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'หากไม่สามารถหาที่ฝึกงานในช่วงนี้ได้ จะต้องดรอปวิชาฝึกงานไหม',\n",
       "  'Work Integrate Leaning หรือ Wil ทำตั้งแต่ช่วงเวลาไหนถึงไหน?',\n",
       "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 3 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวะคอม/วิศวกรรมคอมพิวเตอหลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 3 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิชาภาษาอังกฤษ LNG มีเกณท์การเรื่มเรียนอย่างไร หลักสูตรปกติ ?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ ปีที่ 4 เรียนอะไรบ้าง?',\n",
       "  'วิชาเลือกที่มีวิชาบังคับลงก่อน หลักสูตรนานาชาติ?',\n",
       "  'วิศวะคอม/หลักสูตรนานาชาติปี 2 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ ปีที่ 3 เรียนอะไรบ้าง?',\n",
       "  'วิชา CPE327/Software engineering มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิศวะคอมพิวเตอร์แต่ละหลักสูตรมีระยะเวลาในการศึกษากี่ปี?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ มีกี่หน่วยกิต? ',\n",
       "  'วิศวะคอมหลักสูตรปกติมีระยะเวลาในการศึกษากี่ปี?',\n",
       "  'วิชาภาษาอังกฤษ LNG มีเกณท์การเรื่มเรียนอย่างไร หลักสูตรนานาชาติ ?',\n",
       "  'วิศวะคอมหลักสูตรนานาชาติมีอัตราค่าเรียนเท่าไหร่',\n",
       "  'หากไม่่สามารถฝึกงานได้ต้องทำอย่างไร',\n",
       "  'วิศวะคอม/หลักสูตรปกติ ปี 3 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ มีกี่หน่วยกิต?',\n",
       "  'วิชาภาษาอังกฤษ LNG มีเกณท์การเรื่มเรียนอย่างไร หลักสูตรวิทยาศาสตรบัณฑิต\\nสาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ ?',\n",
       "  'วิศวะคอม/หลักสูตรปกติ ปี 1 เทอม 1 \\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิชา CPE314/Computer networksมีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ ปีที่ 4 เรียนอะไรบ้าง?',\n",
       "  'วิชา CPE326/Operating systems มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ ปีที่ 3 เรียนอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรปกติ  ปี 2 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'หน่วยกิตที่ต้องเก็บให้ครบก่อนจบหรือไม่?',\n",
       "  'วิชา CPE101/Exploration มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'Work Integrate Leaning หรือ Wil จำเป็นที่ลงเลือกวิชาเลือกเสรีหรือไม่?',\n",
       "  'วิศวะคอม/หลักสูตรนานาชาติปี 1 เทอม 1 \\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ ปีที่ 3 เรียนอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 4 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิชาภาคบังคับที่มีตัวต่อเนื่องมีอะไรบ้าง หลักสูตรนานาชาติ?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ ปีที่1-2 เรียนอะไรบ้าง?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ มีกี่หน่วยกิต?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรเรสิเดนทอล คอเลจ ปีที่ 1-2 เรียนอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรปกติ  ปี 3 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
       "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ ปีที่1-2 เรียนอะไรบ้าง?',\n",
       "  'วิชา CPE122/Circuits มีวิชาตัวต่อมั้ยครับ?',\n",
       "  'วิศวะคอมหลักสูตรปกติมีอัตราค่าเรียนเท่าไหร่'],\n",
       " 'การรับเข้านักศึกษา': ['วิศวะคอม/ TCAS รอบ 4 ใช้คะแนนสอบอะไรบ้าง?',\n",
       "  'วิศวะคอม/ TCAS รอบ 3ใช้คะแนนสอบอะไรบ้าง?',\n",
       "  'หลักสูตรHDSมีเกณฑ์การรับยังไงบ้าง?',\n",
       "  'การับสมัครเด็กเข้าเรียน มีทั้งหมดกี่รอบ? อะไรบ้าง?',\n",
       "  'สามารถติดต่อข่าวสารช่องทางการรับสมัครได้ที่ช่องทางไหนบ้าง? ',\n",
       "  'แต่ละหลักสูตรมีเกณฑ์การรับพื้นฐานยังไงบ้าง?',\n",
       "  'หลักสูตรนานาชาติมีเกณฑ์การรับยังไงบ้าง?',\n",
       "  'หลักสูตรปกติมีเกณฑ์การรับยังไงบ้าง?',\n",
       "  'ถ้าจะสมัครเข้าโครงการ Active Recruitment ใช้เอกสารอะไรบ้าง?',\n",
       "  'ถ้าสนใจจะเรียนวิศวะคอม/ เปิดรับเมื่อไหร่ ช่วงไหนบ้าง?',\n",
       "  'วิศวะคอม/ TCAS รอบ 1 มีโครงการไหนเปิดรับบ้าง?',\n",
       "  'วิศวะคอม/ สามารถสมัครเข้าเรียนยังไงได้บ้าง มีรอบอะไรเปิดรับบ้าง?',\n",
       "  'วิศวะคอม/ TCAS รอบ 2 มีโครงการไหนเปิดรับบ้าง?',\n",
       "  'สมัครเข้าโครงการ Active Recruitment ได้อย่างไร?',\n",
       "  'ถ้าจะสมัครเข้าโครงการ Active Recruitment วัดผลยังไง? ดูอะไรบ้าง?',\n",
       "  'จะต้องใช้เอกสารอะไรบ้างในการสมัครเข้าศึกษา'],\n",
       " 'ลงทะเบียนเรียน': ['สามารถลงทะเบียนเกินหน่วยกิตที่หลักสูตรกำหนดได้หรือไม่',\n",
       "  'ใบแจ้งชำระเงินค่าลงทะเบียน สั่งพิมพ์ได้จากที่ไหน',\n",
       "  'ตอนดรอปต้องขอลายเซ็นใครบ้าง?',\n",
       "  'ขอทรานสคริปต์ออนไลน์ได้ที่ไหน',\n",
       "  'ยังต้องเข้าไปเรียนที่มหาลัยไหม?',\n",
       "  'ลงทะเบียนเรียนเพิ่มรายวิชา ชำระเงินได้ที่ไหน?',\n",
       "  'ชำระเงินค่าลงทะเบียนแล้ว แต่ในระบบยังขึ้นว่าไม่ชำระเงิน',\n",
       "  'ถ้าจะดึงบางวิชาลงมาเรียนแทนตัวที่ติด f ได้ไหม ต้องทำอย่างไร',\n",
       "  'ลืมจ่ายเงินค่าลงทะเบียน และ ใบแจ้งหนี้เกินกำหนดไปแล้ว ทำยังไง?',\n",
       "  'ถ้าต้องการลงทะเบียนเรียนน้อยกว่า 9 หน่วยกิตต้องทำอย่างไร?',\n",
       "  'ถ้าการย้ายหลักสูตรต้องทำอย่างไร?',\n",
       "  'ตรวจวันเวลาสอบได้ที่ไหน',\n",
       "  'ขอลดรายวิชาออนไลน์ หลังหมดเขต เพิ่ม-ลด 2 สัปดาห์แรกได้ที่ไหน?',\n",
       "  'กรณีเพิ่มและหลักสูตรปิดรายวิชา จะได้รับเงินคืนไหม หรือ ต้องจ่ายเงินเพิ่มเท่าไหร่',\n",
       "  'แจ้งขอสำเร็จการศึกษาได้ที่ไหน',\n",
       "  'ถ้าต้องการลงทะเบียนเรียนมากกว่า 19 หน่วยกิตต้องทำอย่างไร?',\n",
       "  'วิชาเลือกไหนน่าสนใจ?',\n",
       "  'ลาป่วยต้องทำอย่างไร? ',\n",
       "  'หากมีเหตุต้องพักการเรียน สามารถพักการเรียนตอนนี้ได้ไหม ถ้าได้ต้องทำอย่างไรบ้าง?',\n",
       "  'ต้องการสอบโดยไม่เข้าเรียนได้ไหม?',\n",
       "  'ถ้าต้องการเปลี่ยน section ต้องทำอย่างไร',\n",
       "  'หากจบการศึกษาไม่ทันเกณฑ์ทหารทำยังไง',\n",
       "  'สามารถเช็คคอร์สเรียนออนไลน์ได้ที่ไหน',\n",
       "  'ลงทะเบียนล่าช้าหลังระบบลงทะเบียนปิดที่ไหน',\n",
       "  'ฉันสามารถลงวิชาเสริมในเทอมนี้ได้มากที่สุดกี่ตัว',\n",
       "  'ลากิจต้องทำอย่างไร?',\n",
       "  'ผมอยากลาออกต้องทำยังไง?',\n",
       "  'ถ้าวิชาเรียน sec เต็มแล้วทำยังไง',\n",
       "  'กรณีเพิ่มและลดรายวิชา จะได้รับเงินคืนไหม หรือ ต้องจ่ายเงินเพิ่มเท่าไหร่',\n",
       "  'ดรอปได้ถึงเมื่อไหร่?',\n",
       "  'สามารถเช็คกำหนดการลงทะเบียนเรียนได้ที่ไหน?',\n",
       "  'ลงทะเบียนเรียนล่าช้าใช้เอกสารอะไรบ้าง',\n",
       "  'ตารางสอบซ้อนต้องทำยังไง?',\n",
       "  'อยากได้เอกสารเบิกค่าเทอมต้องเตรียมอะไรบ้าง',\n",
       "  'เรียนต่อต่างประเทศต้องใช้เอกสารอะไรบ้าง',\n",
       "  'ถ้าจะต้องการเอาเครื่องคิดเลขเข้้าห้องสอบต้องทำยังไง',\n",
       "  'ถ้าจะจบการศึกษา แต่เรียน gen ซ้ำหมวดกันทำยังไง'],\n",
       " 'คำถามทั่วไป': ['การส่งคะแนนสอบภาษาอังกฤษเพื่อสำเร็จการศึกษา ส่งอย่างไร?',\n",
       "  'ติดต่อวิศวะคอม/ได้ทางช่องทางไหนได้บ้าง?',\n",
       "  'การสมัครกู้ยืมเรียน ทำอย่างไร?',\n",
       "  'เวลาต้องการยื่นเอกสารต้องยื่นที่ไหน',\n",
       "  'ขั้นตอนและช่วงเวลาเปิดรับสมัครนักศึกษา?',\n",
       "  'เกียรตินิยมอันดับ 2 อยู่ที่เท่าไหร่?',\n",
       "  'วิศวะคอม/หลักสูตรปกติจบแล้วได้ปริญญาอะไร?',\n",
       "  '/วิศวะคอมพิวเตอร์ เรียนจบทำงานอะไร',\n",
       "  'วิศวะคอม/จบไปทำงานอะไร?',\n",
       "  'หลักสูตรนานาชาติจบมาแล้วทำงานในสายใดบ้าง?',\n",
       "  'ใครเป็นหัวหน้าภาควิชาวิศวะคอม/?',\n",
       "  'วิศวะคอม/อยู่ที่ไหน?',\n",
       "  'มีที่ฝึกงานแนะนำไหม?',\n",
       "  'ถ้าอยากไปเรียนต่อต่างและขอทุนต่างประเมศต้องทำอย่างไรบ้าง？',\n",
       "  'สามารถขอทุนอะไรบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรนานาชาติจบแล้วได้ปริญญาอะไร?',\n",
       "  'ปัจจุบันมีทุนอะไรเปิดรับบ้าง?',\n",
       "  'สามารถติดต่ออ.ได้ช่องทางไหนบ้าง?',\n",
       "  'สามารถติดต่อได้ทางช่องทางไหนบ้าง ช่วงเวลากี่โมงถึงกี่โมง?',\n",
       "  'ทุนเพชรพระจอมเกล้าภาควิชารับกี่คน？',\n",
       "  'ทุนจ้างงานคืออะไร？',\n",
       "  'หลักสูตรวิทยาศาสตร์ข้อมูลสุขภาพจบมาแล้วทำงานในสายใดบ้าง?',\n",
       "  'อาจารย์ในภาควิชาวิศวะคอม/มีใครบ้าง? ',\n",
       "  'วิศวะคอม/หลักสูตรวิทยาศาสตร์ข้อมูลสุขภาพจบแล้วได้ปริญญาอะไร?',\n",
       "  'หลักสูตรวิิทยาศาสตร์ข้อมูลสุขภาพคืออะไร?',\n",
       "  'วิศวะคอม/แล้วได้ปริญญาอะไร?',\n",
       "  'เรียนจบต้องใช้คะแนนอังกฤษอะไรบ้าง ขั้นตํ่าเท่าไหร่??',\n",
       "  'เกียรตินิยมอันดับ 1 อยู่ที่เท่าไหร่?',\n",
       "  'มีเงินไม่พอจ่าย ทำอะไรได้บ้าง?',\n",
       "  'วิศวะคอม/แตกต่างจาก IT อย่างไร?',\n",
       "  'วิศวะคอม/เรียนเกี่ยวกับอะไร?',\n",
       "  'หลักสูตรปกติจบมาแล้วทำงานในสายใดบ้าง?',\n",
       "  'ขั้นตอนการรับสมัครโครงการทุนการศึกษา?',\n",
       "  'ทุนของภาควิชามีอะไรบ้าง？',\n",
       "  'หลักสูตรเรสิเดรเทียล คอเจน์จบมาแล้วทำงานในสายใดบ้าง?',\n",
       "  'วิศวะคอม/หลักสูตรเรสิเดนทอล คอลเลจจบแล้วได้ปริญญาอะไร?',\n",
       "  'สมัครหลักสูตรยังไง?']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>หลักสูตร</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ฝึกงาน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ลงทะเบียนเรียน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>การรับเข้านักศึกษา</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ทุนการศึกษา</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>คำถามทั่วไป</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Category\n",
       "0            หลักสูตร\n",
       "1              ฝึกงาน\n",
       "2      ลงทะเบียนเรียน\n",
       "3  การรับเข้านักศึกษา\n",
       "4         ทุนการศึกษา\n",
       "5         คำถามทั่วไป"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"Category.xlsx\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load File\n",
    "with open('token_text_category.data', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    tokenized_texts = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_bow(tokenized_text, vocabulary_):\n",
    "    n_doc = len(tokenized_text)\n",
    "    values, row_indices, col_indices = [], [], []\n",
    "    for r, tokens in enumerate(tokenized_text):\n",
    "        feature = {}\n",
    "        for token in tokens:\n",
    "            word_index = vocabulary_.get(token)\n",
    "            if word_index is not None:\n",
    "                if word_index not in feature.keys():\n",
    "                    feature[word_index] = 1\n",
    "                else:\n",
    "                    feature[word_index] += 1\n",
    "        for c, v in feature.items():\n",
    "            values.append(v)\n",
    "            row_indices.append(r)\n",
    "            col_indices.append(c)\n",
    "        #print(feature)\n",
    "\n",
    "    # document-term matrix in sparse CSR format\n",
    "    X = sp.csr_matrix((values, (row_indices, col_indices)),\n",
    "                      shape=(n_doc, len(vocabulary_)))\n",
    "    return X\n",
    "\n",
    "vocabulary_ = {v: k for k, v in enumerate(set(chain.from_iterable(tokenized_texts)))}\n",
    "X = text_to_bow(tokenized_texts, vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "svd_model = TruncatedSVD(n_components=100,\n",
    "                         algorithm='arpack', n_iter=100)\n",
    "X_tfidf = transformer.fit_transform(X)\n",
    "X_svd = svd_model.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = pd.get_dummies(data.Category).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Load Model\n",
    "logist_models = joblib.load(\"category_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['การรับเข้านักศึกษา', 'คำถามทั่วไป', 'ทุนการศึกษา', 'ฝึกงาน',\n",
      "       'ลงทะเบียนเรียน', 'หลักสูตร'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(np.vstack([model.predict_proba(X_svd)[:, 1] for model in logist_models]).T, axis=1)\n",
    "y_pred = np.array([tag[yi] for yi in y_pred])\n",
    "y_true = data.Category.values\n",
    "print(tag[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9rvOcqWW5sY"
   },
   "source": [
    "# time total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "executionInfo": {
     "elapsed": 1243,
     "status": "ok",
     "timestamp": 1620718089261,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "BjaHxfYqRSKQ",
    "outputId": "9a22dc57-b706-458c-c6ff-ea6fb0e664dd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: วิศวคอมมีหลักสูตรอะไรบ้าง\n",
      "[('การรับเข้านักศึกษา', 0.13460088729294664), ('คำถามทั่วไป', 0.2034823474505967), ('ทุนการศึกษา', 0.050783028033583755), ('ฝึกงาน', 0.0294225354977537), ('ลงทะเบียนเรียน', 0.08308430089106947), ('หลักสูตร', 0.41979603189236847)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e36182fd4f37>:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if w not in wv_model:\n",
      "<ipython-input-13-e36182fd4f37>:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: Work Integrate Leaning หรือ Wil จำเป็นที่ลงเลือกวิชาเลือกเสรีหรือไม่? 0.635234\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#         questions = data[\"questions\"]\n",
    "inputQuestion = \"วิศวคอมมีหลักสูตรอะไรบ้าง\"\n",
    "print('input: ' + inputQuestion)\n",
    "inputQuestion = cleansing(inputQuestion)\n",
    "\n",
    "# Category model\n",
    "tokenized_input_2 = inputQuestion\n",
    "tokenized_text = deepcut.tokenize(tokenized_input_2)\n",
    "x = text_to_bow([tokenized_text], vocabulary_)\n",
    "x_tfidf = transformer.transform(x)\n",
    "x_svd = svd_model.transform(x_tfidf)\n",
    "pred = [model.predict_proba(x_svd.reshape(-1, 1).T).ravel()[1] for model in logist_models]\n",
    "\n",
    "print(list(zip(tag, pred)))\n",
    "predict_category = max(list(zip(tag, pred)))\n",
    "max_value = 0\n",
    "max_category = ''\n",
    "pred_results = list(zip(tag, pred))\n",
    "\n",
    "for pred_result in pred_results:\n",
    "  # print(pred_result)\n",
    "  if pred_result[1] > max_value:\n",
    "    max_value = pred_result[1]\n",
    "    max_category = pred_result[0]\n",
    "questions=questions_data[max_category]\n",
    "\n",
    "# maLSTM\n",
    "newQuestion = {'question1':questions}\n",
    "questionsDB = pd.DataFrame(data=newQuestion)\n",
    "tokenized_category =questionsDB.question1.map(tokenize_text_list)\n",
    "#         print(tokenized_category)\n",
    "\n",
    "max_word = 19219\n",
    "max_seq_length = 2704\n",
    "q_category= []\n",
    "for sentence in tokenized_category:\n",
    "    q_category.append(sentence)\n",
    "q_category = word_index(q_category)\n",
    "all_Question_categorylen = len(q_category)\n",
    "\n",
    "tokenized_dup_input_2= duplicate([tokenized_input_2],all_Question_categorylen)\n",
    "q_user = word_index(tokenized_dup_input_2)\n",
    "# Split to dicts\n",
    "M_input = {'left': q_category, 'right': q_user}\n",
    "# Zero padding\n",
    "for model_input, side in itertools.product([M_input], ['left', 'right']):\n",
    "    model_input[side] = pad_sequences(model_input[side], maxlen=max_seq_length)\n",
    "\n",
    "# Make sure everything is ok\n",
    "assert M_input['left'].shape == M_input['right'].shape\n",
    "play_predict = malstm.predict(x=[M_input['left'],  M_input['right']])\n",
    "max_question_percentage = max(play_predict)\n",
    "question_index = np.where(play_predict == max_question_percentage)\n",
    "predictedQuestion = questionsDB.loc[question_index[0][0],'question1']\n",
    "print('output: '+ predictedQuestion+ ' ' + \"%lf\" % max_question_percentage)\n",
    "value = {\n",
    "  \"predictedQuestion\": predictedQuestion,\n",
    "  \"similarity\": \"%lf\" % max_question_percentage\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#category model\n",
    "inputQuestion = \"วิศวคอมมีหลักสูตรอะไรบ้าง\"\n",
    "tokenized_input_2= cleansing(inputQuestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 64.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_text = deepcut.tokenize(tokenized_input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 968 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = text_to_bow([tokenized_text], vocabulary_)\n",
    "x_tfidf = transformer.transform(x)\n",
    "x_svd = svd_model.transform(x_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 998 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = [model.predict_proba(x_svd.reshape(-1, 1).T).ravel()[1] for model in logist_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print(list(zip(tag, pred)))\n",
    "predict_category = max(list(zip(tag, pred)))\n",
    "max_value = 0\n",
    "max_category = ''\n",
    "pred_results = list(zip(tag, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for pred_result in pred_results:\n",
    "  # print(pred_result)\n",
    "  if pred_result[1] > max_value:\n",
    "    max_value = pred_result[1]\n",
    "    max_category = pred_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# maLSTM\n",
    "questions=questions_data[max_category]\n",
    "newQuestion = {'question1':questions}\n",
    "questionsDB = pd.DataFrame(data=newQuestion)\n",
    "tokenized_category =questionsDB.question1.map(tokenize_text_list)\n",
    "#         print(tokenized_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_word = 19219\n",
    "max_seq_length = 2704\n",
    "q_category= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for sentence in tokenized_category:\n",
    "    q_category.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.99 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e36182fd4f37>:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if w not in wv_model:\n",
      "<ipython-input-13-e36182fd4f37>:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(dataset)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q_category = word_index(q_category)\n",
    "all_Question_categorylen = len(q_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_dup_input_2 = duplicate([tokenized_input_2],all_Question_categorylen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.98 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e36182fd4f37>:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if w not in wv_model:\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q_user = word_index(tokenized_dup_input_2)\n",
    "# Split to dicts\n",
    "M_input = {'left': q_category, 'right': q_user}\n",
    "# Zero padding\n",
    "for model_input, side in itertools.product([M_input], ['left', 'right']):\n",
    "    model_input[side] = pad_sequences(model_input[side], maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make sure everything is ok\n",
    "assert M_input['left'].shape == M_input['right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "play_predict = malstm.predict(x=[M_input['left'],  M_input['right']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_question_percentage = max(play_predict)\n",
    "question_index = np.where(play_predict == max_question_percentage)\n",
    "predictedQuestion = questionsDB.loc[question_index[0][0],'question1']\n",
    "# print('output: '+ predictedQuestion+ ' ' + \"%lf\" % max_question_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = {\n",
    "  \"predictedQuestion\": predictedQuestion,\n",
    "  \"similarity\": \"%lf\" % max_question_percentage\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Siamese_malstm_play.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
