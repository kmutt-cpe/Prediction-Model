{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.19.5 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (1.19.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for tensorflow-gpu: [Errno 2] No such file or directory: 'c:\\\\users\\\\natthawattungruethai\\\\appdata\\\\roaming\\\\python\\\\python38\\\\site-packages\\\\tensorflow_gpu-2.3.0.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.19.5 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py==2.10.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from h5py==2.10.0) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from h5py==2.10.0) (1.19.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for tensorflow-gpu: [Errno 2] No such file or directory: 'c:\\\\users\\\\natthawattungruethai\\\\appdata\\\\roaming\\\\python\\\\python38\\\\site-packages\\\\tensorflow_gpu-2.3.0.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py==2.10.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==3.6.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (3.6.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from gensim==3.6.0) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from gensim==3.6.0) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from gensim==3.6.0) (5.0.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from gensim==3.6.0) (1.19.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for tensorflow-gpu: [Errno 2] No such file or directory: 'c:\\\\users\\\\natthawattungruethai\\\\appdata\\\\roaming\\\\python\\\\python38\\\\site-packages\\\\tensorflow_gpu-2.3.0.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.6.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4035,
     "status": "ok",
     "timestamp": 1620716501332,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "wxRqFag-N8dW",
    "outputId": "b5211c30-c91c-472d-f826-057ad5c61271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepcut in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (0.7.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from deepcut) (1.19.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from deepcut) (2.10.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-win_amd64.whl (6.9 MB)\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from deepcut) (2.2.0rc1)\n",
      "Requirement already satisfied: scipy in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from deepcut) (1.4.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.2.4-cp38-cp38-win_amd64.whl (9.3 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (2.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (1.1.2)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (2.1.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (3.16.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (0.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (0.36.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (1.38.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from tensorflow>=2.0.0->deepcut) (3.3.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow>=2.0.0->deepcut) (1.6.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (2.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (1.30.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->deepcut) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from pandas->deepcut) (2.8.1)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Installing collected packages: threadpoolctl, pytz, joblib, scikit-learn, pandas\n",
      "Successfully installed joblib-1.0.1 pandas-1.2.4 pytz-2021.1 scikit-learn-0.24.2 threadpoolctl-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for tensorflow-gpu: [Errno 2] No such file or directory: 'c:\\\\users\\\\natthawattungruethai\\\\appdata\\\\roaming\\\\python\\\\python38\\\\site-packages\\\\tensorflow_gpu-2.3.0.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install deepcut --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5877,
     "status": "ok",
     "timestamp": 1620716503182,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "rHO_3T9BOGui",
    "outputId": "1a44454f-1da2-4648-cdbb-c18110a79609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pythainlp in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (2.3.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for tensorflow-gpu: [Errno 2] No such file or directory: 'c:\\\\users\\\\natthawattungruethai\\\\appdata\\\\roaming\\\\python\\\\python38\\\\site-packages\\\\tensorflow_gpu-2.3.0.dist-info\\\\METADATA'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from pythainlp) (2.25.1)\n",
      "Requirement already satisfied: tinydb>=3.0 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from pythainlp) (4.4.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from pythainlp) (0.9.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from requests>=2.22.0->pythainlp) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from requests>=2.22.0->pythainlp) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from requests>=2.22.0->pythainlp) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from requests>=2.22.0->pythainlp) (2020.12.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pythainlp --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.4.4-cp38-cp38-win_amd64.whl (270 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from nltk) (1.0.1)\n",
      "Collecting click\n",
      "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.61.0-py2.py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.0.1 nltk-3.6.2 regex-2021.4.4 tqdm-4.61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for tensorflow-gpu: [Errno 2] No such file or directory: 'c:\\\\users\\\\natthawattungruethai\\\\appdata\\\\roaming\\\\python\\\\python38\\\\site-packages\\\\tensorflow_gpu-2.3.0.dist-info\\\\METADATA'\n",
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\NATTHAWATTUNGRUETHAI\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nltk.exe is installed in 'C:\\Users\\NATTHAWATTUNGRUETHAI\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for tensorflow-gpu: [Errno 2] No such file or directory: 'c:\\\\users\\\\natthawattungruethai\\\\appdata\\\\roaming\\\\python\\\\python38\\\\site-packages\\\\tensorflow_gpu-2.3.0.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from flask) (3.0.0)\n",
      "Requirement already satisfied: click>=7.1.2 in c:\\users\\natthawattungruethai\\appdata\\roaming\\python\\python38\\site-packages (from flask) (8.0.1)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from flask) (2.0.1)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from click>=7.1.2->flask) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in c:\\users\\natthawattungruethai\\.conda\\envs\\gpu\\lib\\site-packages (from Jinja2>=3.0->flask) (2.0.1)\n",
      "Installing collected packages: itsdangerous, flask\n",
      "Successfully installed flask-2.0.1 itsdangerous-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for tensorflow-gpu: [Errno 2] No such file or directory: 'c:\\\\users\\\\natthawattungruethai\\\\appdata\\\\roaming\\\\python\\\\python38\\\\site-packages\\\\tensorflow_gpu-2.3.0.dist-info\\\\METADATA'\n",
      "  WARNING: The script flask.exe is installed in 'C:\\Users\\NATTHAWATTUNGRUETHAI\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install flask --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "G9D118ZAOZZB"
   },
   "outputs": [],
   "source": [
    "from pythainlp.corpus import thai_stopwords\n",
    "import deepcut\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, jsonify, request\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5qw6hsPwOmcD"
   },
   "outputs": [],
   "source": [
    "#Clean Text\n",
    "def remove_repettition(text):\n",
    "    token_list = list(text)\n",
    "    if len(token_list) > 2:\n",
    "        filter_list = [True, True]\n",
    "        n = len(token_list)\n",
    "        for i in range(2, n):\n",
    "            if (token_list[i] == token_list[i-1]) and (token_list[i] == token_list[i-2]):\n",
    "                filter_list.append(False)\n",
    "            else:\n",
    "                filter_list.append(True)\n",
    "\n",
    "        output = ''.join(np.array(token_list)[filter_list])\n",
    "    else:\n",
    "        output = text\n",
    "    return output\n",
    "\n",
    "def cleansing(text):\n",
    "    # \\t, \\n, \\xa0 and other special characters. Replace by blank string\n",
    "    text = re.sub('[\\t\\n\\xa0\\\"\\'!?\\/\\(\\)%\\:\\=\\-\\+\\*\\_ๆ]', '', text)\n",
    "    \n",
    "    # Numbers. Replace by space\n",
    "    text = re.sub('[0-9]', ' ', text)\n",
    "    \n",
    "    # Dot. Replace by space\n",
    "    text = re.sub('[\\.]', ' ', text)\n",
    "    \n",
    "    # One or more consecutive space. Replace by single space\n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    \n",
    "    # Remove 2 or more repettition\n",
    "    text = remove_repettition(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NNqVro6LPo8a"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "wv_model = gensim.models.Word2Vec.load('corpus.th.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6cfjBM4tP4UK"
   },
   "outputs": [],
   "source": [
    "def word2idx(word):\n",
    "    index = 0\n",
    "    index = wv_model.wv.vocab[word].index\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oIAJw0p7P7XZ"
   },
   "outputs": [],
   "source": [
    "def word_index(listword):\n",
    "    dataset = []\n",
    "    vocabulary = dict()\n",
    "    inverse_vocabulary = ['<unk>']  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
    "    for sentence in listword:\n",
    "        tmp = []\n",
    "        for w in sentence:\n",
    "            if w not in wv_model:\n",
    "                continue\n",
    "\n",
    "            if w not in vocabulary:\n",
    "                vocabulary[w] = len(inverse_vocabulary)\n",
    "                tmp.append(len(inverse_vocabulary))\n",
    "                inverse_vocabulary.append(w)\n",
    "            else:\n",
    "                tmp.append(word2idx(w))\n",
    "        dataset.append(tmp)\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LO-WyseOP-li"
   },
   "outputs": [],
   "source": [
    "# define word embedding\n",
    "vocab_list = [(k, wv_model.wv[k]) for k, v in wv_model.wv.vocab.items()]\n",
    "embeddings_matrix = np.zeros((len(wv_model.wv.vocab.items()) + 1, wv_model.vector_size))\n",
    "for i in range(len(vocab_list)):\n",
    "    word = vocab_list[i][0]\n",
    "    embeddings_matrix[i + 1] = vocab_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1LVdY7-KDCP9EF2jZebOawVR_3jUQnSGM"
    },
    "executionInfo": {
     "elapsed": 6358,
     "status": "ok",
     "timestamp": 1620716838058,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "YzIv6bWzQC-a",
    "outputId": "14f29683-2dc8-45ec-f731-2f7f617dc726"
   },
   "outputs": [],
   "source": [
    "# vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "XdooUj6QQITq"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "embeddings_matrix = 1 * np.random.randn(len(vocab_list) + 1, EMBEDDING_DIM)  # This will be the embedding matrix\n",
    "embeddings_matrix[0] = 0  # So that the padding will be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0FdjJe_VPdZ0"
   },
   "outputs": [],
   "source": [
    "# Model variables\n",
    "n_hidden = 256\n",
    "batch_size = 128\n",
    "n_epoch = 100\n",
    "max_seq_length = 2704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1620716858559,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "eqK0ymH9QKRy",
    "outputId": "31ac3c38-d119-42ac-f01c-2d5c3a8a06fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.76014451, -0.73600445,  0.89420246, ...,  0.24733923,\n",
       "         1.00154121, -0.05668638],\n",
       "       [-0.62274693, -0.21273356, -0.19482881, ...,  1.27856355,\n",
       "        -1.19812914,  1.41303061],\n",
       "       ...,\n",
       "       [-0.41098705,  0.88387773, -1.47247226, ...,  0.41173911,\n",
       "         1.20978042, -1.20721838],\n",
       "       [ 1.41097323,  0.90917485, -0.78205871, ...,  0.5097654 ,\n",
       "        -0.31080312,  0.18946268],\n",
       "       [ 1.47938183, -0.20076783, -0.19750797, ...,  0.28850249,\n",
       "        -0.72778715,  0.21661161]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "an1uk86LQTio"
   },
   "outputs": [],
   "source": [
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JgPsQ8MlPfWA"
   },
   "outputs": [],
   "source": [
    "# The visible layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(embeddings_matrix), EMBEDDING_DIM, weights=[embeddings_matrix], input_length=max_seq_length, trainable=False)\n",
    "\n",
    "# Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# Since this is a siamese network, both sides share the same LSTM\n",
    "shared_lstm = LSTM(n_hidden)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "# Calculates the distance as defined by the MaLSTM model\n",
    "malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "# Pack it all up into a model\n",
    "malstm = Model([left_input, right_input], [malstm_distance])\n",
    "\n",
    "\n",
    "malstm.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Start training\n",
    "training_start_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1620717012710,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "Nh9milBGQpYY",
    "outputId": "6383054e-67f5-410f-8332-50281e0c54f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2704)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2704)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 2704, 300)    9468300     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          570368      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "==================================================================================================\n",
      "Total params: 10,038,668\n",
      "Trainable params: 570,368\n",
      "Non-trainable params: 9,468,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "malstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "JUOlaUM6OylG"
   },
   "outputs": [],
   "source": [
    "# Load best weight from model\n",
    "malstm.load_weights('sm_colab_ka.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y69P6GtuXAaB"
   },
   "source": [
    "#Test with Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Kjaib296O0US"
   },
   "outputs": [],
   "source": [
    "def prepare_for_predict(input_questions):\n",
    "    q_input= []\n",
    "    cleansing(input_questions)\n",
    "    tokenized_input_1 =deepcut.tokenize(input_questions)\n",
    "    for sentence in tokenized_input_1:\n",
    "      q_input.append(sentence)\n",
    "    q_input= word_index(tokenized_input_1)\n",
    "    q_input = pad_sequences(q_input, maxlen=max_seq_length)\n",
    "    return q_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "w_EAiigkZ51b"
   },
   "outputs": [],
   "source": [
    "#Duplicate list\n",
    "def duplicate(testList, n):\n",
    "    return [ele for ele in testList for _ in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "pL8GEUFCWEKq"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def tokenize_text_list(ls):\n",
    "    \"\"\"Tokenize list of text\"\"\"\n",
    "    return list(chain.from_iterable([deepcut.tokenize(ls)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#หลักสูตร\n",
    "curriculum = ['วิชา CPE332/Professional issuesมีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชาเลือกที่มีวิชาบังคับลงก่อน หลักสูตรปกติ?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 4 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 4 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชาเลือกที่มีวิชาบังคับลงก่อน หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ ?',\n",
    "  'วิชา CPE375/Interactive computingมีวิชาตัวต่อมั้ยครับ?',\n",
    "  'หน่วยกิตที่ต้องเก็บให้ครบก่อนจบหรือไม่?',\n",
    "  'วิศวะคอม/วิศวกรรมคอมพิวเตอหลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 3 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชา CPE224/Computer architectures มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติปี 1 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติปี 1 เทอม 1 \\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชาเลือกที่มีวิชาบังคับลงก่อน หลักสูตรนานาชาติ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ มีกี่หน่วยกิต? ',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ ปีที่1-2 เรียนอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติปี 2 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชา CPE212/Algorithm มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ  ปี 4 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอมหลักสูตรวิทยาศาตร์ข้อมูลสุขภาพมีอัตราค่าเรียนเท่าไหร่',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 3 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชาภาคบังคับที่มีวิชาต่อเนื่อง มีอะไรบ้าง หลักสูตรปกติ?',\n",
    "  'วิชา CPE314/Computer networksมีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรเรสิเดนทอล คอเลจ ปีที่ 1-2 เรียนอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ ปีที่ 3 เรียนอะไรบ้าง?',\n",
    "  'วิชา CPE327/Software engineering มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอมพิวเตอร์แต่ละหลักสูตรมีระยะเวลาในการศึกษากี่ปี?',\n",
    "  'วิชา CPE325/Big data มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชา CPE111/Data Structure มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ ปี 2 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 2 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชาเลือกเสรีต้องลงวิชานอกภาคเท่านั้นหรือไม่?',\n",
    "  'วิศวะคอมหลักสูตรปกติมีอัตราค่าเรียนเท่าไหร่',\n",
    "  'วิชา CPE326/Operating systems มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชา CPE121/Discrete มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ ปีที่ 4 เรียนอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ มีกี่หน่วยกิต?',\n",
    "  'วิชา CPE342/Java programmingมีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชาภาษาอังกฤษ LNG มีเกณท์การเรื่มเรียนอย่างไร หลักสูตรวิทยาศาสตรบัณฑิต\\nสาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ ?',\n",
    "  'วิชา CPE343/Object orientedมีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชา CPE100/Programming มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ มีกี่หน่วยกิต?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 1 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ ปี 3 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ ปีที่1-2 เรียนอะไรบ้าง?',\n",
    "  'วิชา CPE223/Digital มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติปี 4 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชา CPE101/Exploration มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรเรสิเดนทอล คอเลจ ปีที่ 3-4 เรียนอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 3 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชาภาษาอังกฤษ LNG มีเกณท์การเรื่มเรียนอย่างไร หลักสูตรปกติ ?',\n",
    "  'วิชาภาคบังคับที่มีตัวต่อเนื่องมีอะไรบ้าง หลักสูตรนานาชาติ?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ  ปี 3 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ ปีที่1-2 เรียนอะไรบ้าง?',\n",
    "  'วิชา CPE231/Database มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชาภาคบังคับที่มีวิชาต่อเนื่อง  หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nมีอะไรบ้าง ?',\n",
    "  'วิชาภาษาอังกฤษ LNG มีเกณท์การเรื่มเรียนอย่างไร หลักสูตรนานาชาติ ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ ปีที่ 3 เรียนอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ  ปี 2 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ ปี 1 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอมหลักสูตรปกติมีระยะเวลาในการศึกษากี่ปี?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 2 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชา CPE213/Data model วิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 1 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/ มีทั้งหมดกี่หลักสูตร? มีหลักสูตรอะไรบ้าง?',\n",
    "  'วิศวะคอมหลักสูตรนานาชาติมีอัตราค่าเรียนเท่าไหร่',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 4 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ ปีที่ 4 เรียนอะไรบ้าง?',\n",
    "  'วิชา CPE122/Circuits มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ  ปี 4 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ ปีที่ 3 เรียนอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 3 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชา CPE329/Business intelligence มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 2 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ ปีที่ 4 เรียนอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ ปี 1 เทอม 1 \\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'ชำระเงินค่าลงทะเบียนแล้ว แต่ในระบบยังขึ้นว่าไม่ชำระเงิน',\n",
    "  'ถ้าต้องการลงทะเบียนเรียนน้อยกว่า 9 หน่วยกิตต้องทำอย่างไร?',\n",
    "  'ลากิจต้องทำอย่างไร?',\n",
    "  'ผมอยากลาออกต้องทำยังไง?',\n",
    "  'ใบแจ้งชำระเงินค่าลงทะเบียน สั่งพิมพ์ได้จากที่ไหน',\n",
    "  'แจ้งขอสำเร็จการศึกษาได้ที่ไหน',\n",
    "  'ถ้าวิชาเรียน sec เต็มแล้วทำยังไง',\n",
    "  'ถ้าจะจบการศึกษา แต่เรียน gen ซ้ำหมวดกันทำยังไง',\n",
    "  'ลงทะเบียนเรียนล่าช้าใช้เอกสารอะไรบ้าง',\n",
    "  'หากมีเหตุต้องพักการเรียน สามารถพักการเรียนตอนนี้ได้ไหม ถ้าได้ต้องทำอย่างไรบ้าง?',\n",
    "  'ดรอปได้ถึงเมื่อไหร่?',\n",
    "  'สามารถเช็คกำหนดการลงทะเบียนเรียนได้ที่ไหน?',\n",
    "  'ต้องการสอบโดยไม่เข้าเรียนได้ไหม?',\n",
    "  'ยังต้องเข้าไปเรียนที่มหาลัยไหม?',\n",
    "  'ลืมจ่ายเงินค่าลงทะเบียน และ ใบแจ้งหนี้เกินกำหนดไปแล้ว ทำยังไง?',\n",
    "  'ลาป่วยต้องทำอย่างไร? ',\n",
    "  'ตารางสอบซ้อนต้องทำยังไง?',\n",
    "  'ฉันสามารถลงวิชาเสริมในเทอมนี้ได้มากที่สุดกี่ตัว',\n",
    "  'ถ้าจะต้องการเอาเครื่องคิดเลขเข้้าห้องสอบต้องทำยังไง',\n",
    "  'ถ้าต้องการลงทะเบียนเรียนมากกว่า 19 หน่วยกิตต้องทำอย่างไร?',\n",
    "  'กรณีเพิ่มและหลักสูตรปิดรายวิชา จะได้รับเงินคืนไหม หรือ ต้องจ่ายเงินเพิ่มเท่าไหร่',\n",
    "  'ลงทะเบียนเรียนเพิ่มรายวิชา ชำระเงินได้ที่ไหน?',\n",
    "  'อยากได้เอกสารเบิกค่าเทอมต้องเตรียมอะไรบ้าง',\n",
    "  'ตอนดรอปต้องขอลายเซ็นใครบ้าง?',\n",
    "  'ตรวจวันเวลาสอบได้ที่ไหน',\n",
    "  'สามารถลงทะเบียนเกินหน่วยกิตที่หลักสูตรกำหนดได้หรือไม่',\n",
    "  'เรียนต่อต่างประเทศต้องใช้เอกสารอะไรบ้าง',\n",
    "  'หากจบการศึกษาไม่ทันเกณฑ์ทหารทำยังไง',\n",
    "  'ลงทะเบียนล่าช้าหลังระบบลงทะเบียนปิดที่ไหน',\n",
    "  'ถ้าการย้ายหลักสูตรต้องทำอย่างไร?',\n",
    "  'กรณีเพิ่มและลดรายวิชา จะได้รับเงินคืนไหม หรือ ต้องจ่ายเงินเพิ่มเท่าไหร่',\n",
    "  'สามารถเช็คคอร์สเรียนออนไลน์ได้ที่ไหน',\n",
    "  'ถ้าจะดึงบางวิชาลงมาเรียนแทนตัวที่ติด f ได้ไหม ต้องทำอย่างไร',\n",
    "  'วิชาเลือกไหนน่าสนใจ?',\n",
    "  'ขอทรานสคริปต์ออนไลน์ได้ที่ไหน',\n",
    "  'ถ้าต้องการเปลี่ยน section ต้องทำอย่างไร',\n",
    "  'ขอลดรายวิชาออนไลน์ หลังหมดเขต เพิ่ม-ลด 2 สัปดาห์แรกได้ที่ไหน?',\n",
    "  'วิศวะคอม/ TCAS รอบ 2 มีโครงการไหนเปิดรับบ้าง?',\n",
    "  'ถ้าจะสมัครเข้าโครงการ Active Recruitment วัดผลยังไง? ดูอะไรบ้าง?',\n",
    "  'วิศวะคอม/ TCAS รอบ 4 ใช้คะแนนสอบอะไรบ้าง?',\n",
    "  'หลักสูตรปกติมีเกณฑ์การรับยังไงบ้าง?',\n",
    "  'หลักสูตรHDSมีเกณฑ์การรับยังไงบ้าง?',\n",
    "  'สมัครเข้าโครงการ Active Recruitment ได้อย่างไร?',\n",
    "  'วิศวะคอม/ TCAS รอบ 3ใช้คะแนนสอบอะไรบ้าง?',\n",
    "  'หลักสูตรนานาชาติมีเกณฑ์การรับยังไงบ้าง?',\n",
    "  'ถ้าสนใจจะเรียนวิศวะคอม/ เปิดรับเมื่อไหร่ ช่วงไหนบ้าง?',\n",
    "  'วิศวะคอม/ สามารถสมัครเข้าเรียนยังไงได้บ้าง มีรอบอะไรเปิดรับบ้าง?',\n",
    "  'แต่ละหลักสูตรมีเกณฑ์การรับพื้นฐานยังไงบ้าง?',\n",
    "  'ถ้าจะสมัครเข้าโครงการ Active Recruitment ใช้เอกสารอะไรบ้าง?',\n",
    "  'วิศวะคอม/ TCAS รอบ 1 มีโครงการไหนเปิดรับบ้าง?',\n",
    "  'การับสมัครเด็กเข้าเรียน มีทั้งหมดกี่รอบ? อะไรบ้าง?',\n",
    "  'สามารถติดต่อข่าวสารช่องทางการรับสมัครได้ที่ช่องทางไหนบ้าง? ',\n",
    "  'จะต้องใช้เอกสารอะไรบ้างในการสมัครเข้าศึกษา',\n",
    "  'ถ้าไม่ได้เป็นนักศึกษาชั้นปีที่ 3 สามารถฝึกงานได้หรือไม่？',\n",
    "  'หากไม่สามารถหาที่ฝึกงานในช่วงนี้ได้ จะต้องดรอปวิชาฝึกงานไหม',\n",
    "  'Work Integrate Leaning หรือ Wil จำเป็นที่ลงเลือกวิชาเลือกเสรีหรือไม่?',\n",
    "  'หากไม่่สามารถฝึกงานได้ต้องทำอย่างไร',\n",
    "  'ถ้าต้องการฝึกงานต้องทำอย่างไรบ้าง?',\n",
    "  'ฝึกงานจำเป็นต้องครบ40ชั่วโมงไหม？',\n",
    "  'Work Integrate Leaning หรือ Wil ทำตั้งแต่ช่วงเวลาไหนถึงไหน?',\n",
    "  'ถ้าต้องการทำ Work Integrate Leaning หรือ Wil ต้องทำอย่างไร?',\n",
    "  'เวลาต้องการยื่นเอกสารต้องยื่นที่ไหน',\n",
    "  'วิศวะคอม/หลักสูตรเรสิเดนทอล คอลเลจจบแล้วได้ปริญญาอะไร?',\n",
    "  'ขั้นตอนและช่วงเวลาเปิดรับสมัครนักศึกษา?',\n",
    "  'หลักสูตรวิทยาศาสตร์ข้อมูลสุขภาพจบมาแล้วทำงานในสายใดบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรปกติจบแล้วได้ปริญญาอะไร?',\n",
    "  'เรียนจบต้องใช้คะแนนอังกฤษอะไรบ้าง ขั้นตํ่าเท่าไหร่??',\n",
    "  'หลักสูตรนานาชาติจบมาแล้วทำงานในสายใดบ้าง?',\n",
    "  'สามารถติดต่ออ.ได้ช่องทางไหนบ้าง?',\n",
    "  'สมัครหลักสูตรยังไง?',\n",
    "  'ขั้นตอนการรับสมัครโครงการทุนการศึกษา?',\n",
    "  'วิศวะคอม/เรียนเกี่ยวกับอะไร?',\n",
    "  '/วิศวะคอมพิวเตอร์ เรียนจบทำงานอะไร',\n",
    "  'การส่งคะแนนสอบภาษาอังกฤษเพื่อสำเร็จการศึกษา ส่งอย่างไร?',\n",
    "  'ใครเป็นหัวหน้าภาควิชาวิศวะคอม/?',\n",
    "  'มีที่ฝึกงานแนะนำไหม?',\n",
    "  'ติดต่อวิศวะคอม/ได้ทางช่องทางไหนได้บ้าง?',\n",
    "  'สามารถติดต่อได้ทางช่องทางไหนบ้าง ช่วงเวลากี่โมงถึงกี่โมง?',\n",
    "  'หลักสูตรเรสิเดรเทียล คอเจน์จบมาแล้วทำงานในสายใดบ้าง?',\n",
    "  'วิศวะคอม/แตกต่างจาก IT อย่างไร?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตร์ข้อมูลสุขภาพจบแล้วได้ปริญญาอะไร?',\n",
    "  'เกียรตินิยมอันดับ 2 อยู่ที่เท่าไหร่?',\n",
    "  'หลักสูตรวิิทยาศาสตร์ข้อมูลสุขภาพคืออะไร?',\n",
    "  'วิศวะคอม/จบไปทำงานอะไร?',\n",
    "  'อาจารย์ในภาควิชาวิศวะคอม/มีใครบ้าง? ',\n",
    "  'เกียรตินิยมอันดับ 1 อยู่ที่เท่าไหร่?',\n",
    "  'หลักสูตรปกติจบมาแล้วทำงานในสายใดบ้าง?',\n",
    "  'วิศวะคอม/แล้วได้ปริญญาอะไร?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติจบแล้วได้ปริญญาอะไร?',\n",
    "  'วิศวะคอม/อยู่ที่ไหน?',\n",
    "  'สามารถขอทุนอะไรบ้าง?',\n",
    "  'ทุนเพชรพระจอมเกล้าภาควิชารับกี่คน？',\n",
    "  'ทุนของภาควิชามีอะไรบ้าง？',\n",
    "  'การสมัครกู้ยืมเรียน ทำอย่างไร?',\n",
    "  'ถ้าอยากไปเรียนต่อต่างและขอทุนต่างประเมศต้องทำอย่างไรบ้าง？',\n",
    "  'มีเงินไม่พอจ่าย ทำอะไรได้บ้าง?',\n",
    "  'ทุนจ้างงานคืออะไร？',\n",
    "  'ปัจจุบันมีทุนอะไรเปิดรับบ้าง?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-e36182fd4f37>:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if w not in wv_model:\n",
      "<ipython-input-19-e36182fd4f37>:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: ติดต่อวิศวะคอม/ได้ทางช่องทางไหนได้บ้าง? 0.998395\n",
      "Wall time: 46.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "curriculumObj = {'curriculum':curriculum}\n",
    "curriculumDF = pd.DataFrame(data=curriculumObj)\n",
    "beforeTok = {}\n",
    "beforeTok['หลักสูตร'] = curriculumDF\n",
    "tokenized_curriculum =curriculumDF.curriculum.map(tokenize_text_list)\n",
    "max_word = 19219\n",
    "max_seq_length = 2704\n",
    "q_category= []\n",
    "for sentence in tokenized_curriculum:\n",
    "    q_category.append(sentence)\n",
    "q_category = word_index(q_category)\n",
    "all_Question_categorylen = len(q_category)\n",
    "all_Question_categorylen\n",
    "input2 = 'วิศวคอมมีหลักสูตรอะไรบ้าง'\n",
    "tokenized_input_2=cleansing(input2)\n",
    "tokenized_input_2 =deepcut.tokenize(tokenized_input_2)\n",
    "tokenized_dup_input_2= duplicate([tokenized_input_2],all_Question_categorylen)\n",
    "q_user = word_index(tokenized_dup_input_2)\n",
    "# Split to dicts\n",
    "M_input = {'left': q_category, 'right': q_user}\n",
    "# Zero padding\n",
    "for model_input, side in itertools.product([M_input], ['left', 'right']):\n",
    "    model_input[side] = pad_sequences(model_input[side], maxlen=max_seq_length)\n",
    "\n",
    "# Make sure everything is ok\n",
    "assert M_input['left'].shape == M_input['right'].shape\n",
    "play_predict = malstm.predict(x=[M_input['left'],  M_input['right']])\n",
    "max_question_percentage = max(play_predict)\n",
    "question_index = np.where(play_predict == max_question_percentage)\n",
    "predictedQuestion = curriculum[question_index[0][0]]\n",
    "print('output: '+ predictedQuestion+ ' ' + \"%lf\" % max_question_percentage)\n",
    "value = {\n",
    "  \"predictedQuestion\": predictedQuestion,\n",
    "  \"similarity\": \"%lf\" % max_question_percentage\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "curriculumObj = {'curriculum':curriculum}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 998 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "curriculumDF = pd.DataFrame(data=curriculumObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "beforeTok = {}\n",
    "beforeTok['หลักสูตร'] = curriculumDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "BsY51Xn9WTBS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_curriculum =curriculumDF.curriculum.map(tokenize_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "CGdqwM2qWt0r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_word = 19219\n",
    "max_seq_length = 2704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "1XpFqeXNWuux"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 998 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q_category= []\n",
    "for sentence in tokenized_curriculum:\n",
    "    q_category.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1780,
     "status": "ok",
     "timestamp": 1620718746721,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "UAWaItX5VMgx",
    "outputId": "b98d6b35-47da-474b-c57f-761560da32ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.98 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-e36182fd4f37>:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if w not in wv_model:\n",
      "<ipython-input-19-e36182fd4f37>:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(dataset)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q_category = word_index(q_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 983,
     "status": "ok",
     "timestamp": 1620719336702,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "tuC_yktbZW3r",
    "outputId": "1fc8fba7-ff9c-422d-cf7b-c9bb68e8efb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "all_Question_categorylen = len(q_category)\n",
    "all_Question_categorylen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GHSbyPrYTtR"
   },
   "source": [
    "#Question from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "9hiwFzS5YSwC"
   },
   "outputs": [],
   "source": [
    "input2 = 'วิศวคอมมีหลักสูตรอะไรบ้าง'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6brFZaZWYjiM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_input_2=cleansing(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 72.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_input_2 =deepcut.tokenize(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1620719906256,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "mWT7jP6eaWrq",
    "outputId": "2228f3a8-cf2b-41a5-cc34-7e074a6b24de",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_dup_input_2= duplicate([tokenized_input_2],all_Question_categorylen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1620720299412,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "KWz3M_DaYQAh",
    "outputId": "a1c2da27-e31e-4507-9eb3-87ca3160217c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.99 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-e36182fd4f37>:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if w not in wv_model:\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q_user = word_index(tokenized_dup_input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "IJsfJNSmdO4P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Split to dicts\n",
    "M_input = {'left': q_category, 'right': q_user}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "0zcdoqaUd_Zm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Zero padding\n",
    "for model_input, side in itertools.product([M_input], ['left', 'right']):\n",
    "    model_input[side] = pad_sequences(model_input[side], maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make sure everything is ok\n",
    "assert M_input['left'].shape == M_input['right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "QQjSaocQeck_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "play_predict = malstm.predict(x=[M_input['left'],  M_input['right']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_question_percentage = max(play_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question_index = np.where(play_predict == max_question_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictedQuestion = beforeTok['หลักสูตร'].loc[question_index[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 998 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = {\n",
    "          \"predictedQuestion\": str(predictedQuestion),\n",
    "          \"similarity\": \"%lf\" % max_question_percentage\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'{\"predictedQuestion\": \"curriculum    \\xe0\\xb8\\x95\\xe0\\xb8\\xb4\\xe0\\xb8\\x94\\xe0\\xb8\\x95\\xe0\\xb9\\x88\\xe0\\xb8\\xad\\xe0\\xb8\\xa7\\xe0\\xb8\\xb4\\xe0\\xb8\\xa8\\xe0\\xb8\\xa7\\xe0\\xb8\\xb0\\xe0\\xb8\\x84\\xe0\\xb8\\xad\\xe0\\xb8\\xa1/\\xe0\\xb9\\x84\\xe0\\xb8\\x94\\xe0\\xb9\\x89\\xe0\\xb8\\x97\\xe0\\xb8\\xb2\\xe0\\xb8\\x87\\xe0\\xb8\\x8a\\xe0\\xb9\\x88\\xe0\\xb8\\xad\\xe0\\xb8\\x87\\xe0\\xb8\\x97\\xe0\\xb8\\xb2\\xe0\\xb8\\x87\\xe0\\xb9\\x84\\xe0\\xb8\\xab\\xe0\\xb8\\x99\\xe0\\xb9\\x84\\xe0\\xb8\\x94\\xe0\\xb9\\x89\\xe0\\xb8\\x9a\\xe0\\xb9\\x89\\xe0\\xb8\\xb2\\xe0\\xb8\\x87?\\\\nName: 150, dtype: object\", \"similarity\": \"0.998395\"}'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "json.dumps(value, ensure_ascii=False).encode('utf8')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Siamese_malstm_play.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
