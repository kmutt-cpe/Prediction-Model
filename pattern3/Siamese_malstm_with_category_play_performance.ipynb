{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.19.5 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py==2.10.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim==3.6.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4035,
     "status": "ok",
     "timestamp": 1620716501332,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "wxRqFag-N8dW",
    "outputId": "b5211c30-c91c-472d-f826-057ad5c61271"
   },
   "outputs": [],
   "source": [
    "!pip install deepcut --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5877,
     "status": "ok",
     "timestamp": 1620716503182,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "rHO_3T9BOGui",
    "outputId": "1a44454f-1da2-4648-cdbb-c18110a79609"
   },
   "outputs": [],
   "source": [
    "!pip install pythainlp --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G9D118ZAOZZB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NATTHAWATTUNGRUETHAI\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "import deepcut\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Category model import\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import joblib\n",
    "\n",
    "#api\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, jsonify, request\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>หลักสูตร</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ฝึกงาน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ลงทะเบียนเรียน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>การรับเข้านักศึกษา</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ทุนการศึกษา</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>คำถามทั่วไป</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Category\n",
       "0            หลักสูตร\n",
       "1              ฝึกงาน\n",
       "2      ลงทะเบียนเรียน\n",
       "3  การรับเข้านักศึกษา\n",
       "4         ทุนการศึกษา\n",
       "5         คำถามทั่วไป"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"Category.xlsx\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load File\n",
    "with open('token_text_category.data', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    tokenized_texts = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pL8GEUFCWEKq"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def tokenize_text_list(ls):\n",
    "    \"\"\"Tokenize list of text\"\"\"\n",
    "    return list(chain.from_iterable([deepcut.tokenize(ls)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_bow(tokenized_text, vocabulary_):\n",
    "    n_doc = len(tokenized_text)\n",
    "    values, row_indices, col_indices = [], [], []\n",
    "    for r, tokens in enumerate(tokenized_text):\n",
    "        feature = {}\n",
    "        for token in tokens:\n",
    "            word_index = vocabulary_.get(token)\n",
    "            if word_index is not None:\n",
    "                if word_index not in feature.keys():\n",
    "                    feature[word_index] = 1\n",
    "                else:\n",
    "                    feature[word_index] += 1\n",
    "        for c, v in feature.items():\n",
    "            values.append(v)\n",
    "            row_indices.append(r)\n",
    "            col_indices.append(c)\n",
    "        #print(feature)\n",
    "\n",
    "    # document-term matrix in sparse CSR format\n",
    "    X = sp.csr_matrix((values, (row_indices, col_indices)),\n",
    "                      shape=(n_doc, len(vocabulary_)))\n",
    "    return X\n",
    "\n",
    "vocabulary_ = {v: k for k, v in enumerate(set(chain.from_iterable(tokenized_texts)))}\n",
    "X = text_to_bow(tokenized_texts, vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "svd_model = TruncatedSVD(n_components=100,\n",
    "                         algorithm='arpack', n_iter=100)\n",
    "X_tfidf = transformer.fit_transform(X)\n",
    "X_svd = svd_model.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = pd.get_dummies(data.Category).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Lib\n",
    "import joblib\n",
    "\n",
    "#Load Model\n",
    "logist_models = joblib.load(\"category_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['การรับเข้านักศึกษา', 'คำถามทั่วไป', 'ทุนการศึกษา', 'ฝึกงาน',\n",
      "       'ลงทะเบียนเรียน', 'หลักสูตร'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(np.vstack([model.predict_proba(X_svd)[:, 1] for model in logist_models]).T, axis=1)\n",
    "y_pred = np.array([tag[yi] for yi in y_pred])\n",
    "y_true = data.Category.values\n",
    "print(tag[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5qw6hsPwOmcD"
   },
   "outputs": [],
   "source": [
    "#Clean Text\n",
    "def remove_repettition(text):\n",
    "    token_list = list(text)\n",
    "    if len(token_list) > 2:\n",
    "        filter_list = [True, True]\n",
    "        n = len(token_list)\n",
    "        for i in range(2, n):\n",
    "            if (token_list[i] == token_list[i-1]) and (token_list[i] == token_list[i-2]):\n",
    "                filter_list.append(False)\n",
    "            else:\n",
    "                filter_list.append(True)\n",
    "\n",
    "        output = ''.join(np.array(token_list)[filter_list])\n",
    "    else:\n",
    "        output = text\n",
    "    return output\n",
    "\n",
    "def cleansing(text):\n",
    "    # \\t, \\n, \\xa0 and other special characters. Replace by blank string\n",
    "    text = re.sub('[\\t\\n\\xa0\\\"\\'!?\\/\\(\\)%\\:\\=\\-\\+\\*\\_ๆ]', '', text)\n",
    "    \n",
    "    # Numbers. Replace by space\n",
    "    text = re.sub('[0-9]', ' ', text)\n",
    "    \n",
    "    # Dot. Replace by space\n",
    "    text = re.sub('[\\.]', ' ', text)\n",
    "    \n",
    "    # One or more consecutive space. Replace by single space\n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    \n",
    "    # Remove 2 or more repettition\n",
    "    text = remove_repettition(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NNqVro6LPo8a"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "wv_model = gensim.models.Word2Vec.load('corpus.th.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6cfjBM4tP4UK"
   },
   "outputs": [],
   "source": [
    "def word2idx(word):\n",
    "    index = 0\n",
    "    index = wv_model.wv.vocab[word].index\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oIAJw0p7P7XZ"
   },
   "outputs": [],
   "source": [
    "def word_index(listword):\n",
    "    dataset = []\n",
    "    vocabulary = dict()\n",
    "    inverse_vocabulary = ['<unk>']  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
    "    for sentence in listword:\n",
    "        tmp = []\n",
    "        for w in sentence:\n",
    "            if w not in wv_model:\n",
    "                continue\n",
    "\n",
    "            if w not in vocabulary:\n",
    "                vocabulary[w] = len(inverse_vocabulary)\n",
    "                tmp.append(len(inverse_vocabulary))\n",
    "                inverse_vocabulary.append(w)\n",
    "            else:\n",
    "                tmp.append(word2idx(w))\n",
    "        dataset.append(tmp)\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LO-WyseOP-li"
   },
   "outputs": [],
   "source": [
    "# define word embedding\n",
    "vocab_list = [(k, wv_model.wv[k]) for k, v in wv_model.wv.vocab.items()]\n",
    "embeddings_matrix = np.zeros((len(wv_model.wv.vocab.items()) + 1, wv_model.vector_size))\n",
    "for i in range(len(vocab_list)):\n",
    "    word = vocab_list[i][0]\n",
    "    embeddings_matrix[i + 1] = vocab_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1LVdY7-KDCP9EF2jZebOawVR_3jUQnSGM"
    },
    "executionInfo": {
     "elapsed": 6358,
     "status": "ok",
     "timestamp": 1620716838058,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "YzIv6bWzQC-a",
    "outputId": "14f29683-2dc8-45ec-f731-2f7f617dc726"
   },
   "outputs": [],
   "source": [
    "# vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XdooUj6QQITq"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "embeddings_matrix = 1 * np.random.randn(len(vocab_list) + 1, EMBEDDING_DIM)  # This will be the embedding matrix\n",
    "embeddings_matrix[0] = 0  # So that the padding will be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0FdjJe_VPdZ0"
   },
   "outputs": [],
   "source": [
    "# Model variables\n",
    "n_hidden = 256\n",
    "batch_size = 128\n",
    "n_epoch = 100\n",
    "max_seq_length = 2704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1620716858559,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "eqK0ymH9QKRy",
    "outputId": "31ac3c38-d119-42ac-f01c-2d5c3a8a06fe"
   },
   "outputs": [],
   "source": [
    "# embeddings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "an1uk86LQTio"
   },
   "outputs": [],
   "source": [
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JgPsQ8MlPfWA"
   },
   "outputs": [],
   "source": [
    "# The visible layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(embeddings_matrix), EMBEDDING_DIM, weights=[embeddings_matrix], input_length=max_seq_length, trainable=False)\n",
    "\n",
    "# Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# Since this is a siamese network, both sides share the same LSTM\n",
    "shared_lstm = LSTM(n_hidden)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "# Calculates the distance as defined by the MaLSTM model\n",
    "malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "# Pack it all up into a model\n",
    "malstm = Model([left_input, right_input], [malstm_distance])\n",
    "\n",
    "\n",
    "malstm.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Start training\n",
    "training_start_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1620717012710,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "Nh9milBGQpYY",
    "outputId": "6383054e-67f5-410f-8332-50281e0c54f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2704)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2704)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 2704, 300)    9468300     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          570368      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "==================================================================================================\n",
      "Total params: 10,038,668\n",
      "Trainable params: 570,368\n",
      "Non-trainable params: 9,468,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "malstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JUOlaUM6OylG"
   },
   "outputs": [],
   "source": [
    "# Load best weight from model\n",
    "malstm.load_weights('sm_colab_ka.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y69P6GtuXAaB"
   },
   "source": [
    "#Test with Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Kjaib296O0US"
   },
   "outputs": [],
   "source": [
    "def prepare_for_predict(input_questions):\n",
    "    q_input= []\n",
    "    cleansing(input_questions)\n",
    "    tokenized_input_1 =deepcut.tokenize(input_questions)\n",
    "    for sentence in tokenized_input_1:\n",
    "      q_input.append(sentence)\n",
    "    q_input= word_index(tokenized_input_1)\n",
    "    q_input = pad_sequences(q_input, maxlen=max_seq_length)\n",
    "    return q_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "CGdqwM2qWt0r"
   },
   "outputs": [],
   "source": [
    "max_word = 19219\n",
    "max_seq_length = 2704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicate list\n",
    "def duplicate(testList, n):\n",
    "    return [ele for ele in testList for _ in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data from all category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ลงทะเบียนเรียน\n",
    "enrollment = ['ชำระเงินค่าลงทะเบียนแล้ว แต่ในระบบยังขึ้นว่าไม่ชำระเงิน',\n",
    "  'ถ้าต้องการลงทะเบียนเรียนน้อยกว่า 9 หน่วยกิตต้องทำอย่างไร?',\n",
    "  'ลากิจต้องทำอย่างไร?',\n",
    "  'ผมอยากลาออกต้องทำยังไง?',\n",
    "  'ใบแจ้งชำระเงินค่าลงทะเบียน สั่งพิมพ์ได้จากที่ไหน',\n",
    "  'แจ้งขอสำเร็จการศึกษาได้ที่ไหน',\n",
    "  'ถ้าวิชาเรียน sec เต็มแล้วทำยังไง',\n",
    "  'ถ้าจะจบการศึกษา แต่เรียน gen ซ้ำหมวดกันทำยังไง',\n",
    "  'ลงทะเบียนเรียนล่าช้าใช้เอกสารอะไรบ้าง',\n",
    "  'หากมีเหตุต้องพักการเรียน สามารถพักการเรียนตอนนี้ได้ไหม ถ้าได้ต้องทำอย่างไรบ้าง?',\n",
    "  'ดรอปได้ถึงเมื่อไหร่?',\n",
    "  'สามารถเช็คกำหนดการลงทะเบียนเรียนได้ที่ไหน?',\n",
    "  'ต้องการสอบโดยไม่เข้าเรียนได้ไหม?',\n",
    "  'ยังต้องเข้าไปเรียนที่มหาลัยไหม?',\n",
    "  'ลืมจ่ายเงินค่าลงทะเบียน และ ใบแจ้งหนี้เกินกำหนดไปแล้ว ทำยังไง?',\n",
    "  'ลาป่วยต้องทำอย่างไร? ',\n",
    "  'ตารางสอบซ้อนต้องทำยังไง?',\n",
    "  'ฉันสามารถลงวิชาเสริมในเทอมนี้ได้มากที่สุดกี่ตัว',\n",
    "  'ถ้าจะต้องการเอาเครื่องคิดเลขเข้้าห้องสอบต้องทำยังไง',\n",
    "  'ถ้าต้องการลงทะเบียนเรียนมากกว่า 19 หน่วยกิตต้องทำอย่างไร?',\n",
    "  'กรณีเพิ่มและหลักสูตรปิดรายวิชา จะได้รับเงินคืนไหม หรือ ต้องจ่ายเงินเพิ่มเท่าไหร่',\n",
    "  'ลงทะเบียนเรียนเพิ่มรายวิชา ชำระเงินได้ที่ไหน?',\n",
    "  'อยากได้เอกสารเบิกค่าเทอมต้องเตรียมอะไรบ้าง',\n",
    "  'ตอนดรอปต้องขอลายเซ็นใครบ้าง?',\n",
    "  'ตรวจวันเวลาสอบได้ที่ไหน',\n",
    "  'สามารถลงทะเบียนเกินหน่วยกิตที่หลักสูตรกำหนดได้หรือไม่',\n",
    "  'เรียนต่อต่างประเทศต้องใช้เอกสารอะไรบ้าง',\n",
    "  'หากจบการศึกษาไม่ทันเกณฑ์ทหารทำยังไง',\n",
    "  'ลงทะเบียนล่าช้าหลังระบบลงทะเบียนปิดที่ไหน',\n",
    "  'ถ้าการย้ายหลักสูตรต้องทำอย่างไร?',\n",
    "  'กรณีเพิ่มและลดรายวิชา จะได้รับเงินคืนไหม หรือ ต้องจ่ายเงินเพิ่มเท่าไหร่',\n",
    "  'สามารถเช็คคอร์สเรียนออนไลน์ได้ที่ไหน',\n",
    "  'ถ้าจะดึงบางวิชาลงมาเรียนแทนตัวที่ติด f ได้ไหม ต้องทำอย่างไร',\n",
    "  'วิชาเลือกไหนน่าสนใจ?',\n",
    "  'ขอทรานสคริปต์ออนไลน์ได้ที่ไหน',\n",
    "  'ถ้าต้องการเปลี่ยน section ต้องทำอย่างไร',\n",
    "  'ขอลดรายวิชาออนไลน์ หลังหมดเขต เพิ่ม-ลด 2 สัปดาห์แรกได้ที่ไหน?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# การรับเข้านักศึกษา\n",
    "admission = ['วิศวะคอม/ TCAS รอบ 2 มีโครงการไหนเปิดรับบ้าง?',\n",
    "  'ถ้าจะสมัครเข้าโครงการ Active Recruitment วัดผลยังไง? ดูอะไรบ้าง?',\n",
    "  'วิศวะคอม/ TCAS รอบ 4 ใช้คะแนนสอบอะไรบ้าง?',\n",
    "  'หลักสูตรปกติมีเกณฑ์การรับยังไงบ้าง?',\n",
    "  'หลักสูตรHDSมีเกณฑ์การรับยังไงบ้าง?',\n",
    "  'สมัครเข้าโครงการ Active Recruitment ได้อย่างไร?',\n",
    "  'วิศวะคอม/ TCAS รอบ 3ใช้คะแนนสอบอะไรบ้าง?',\n",
    "  'หลักสูตรนานาชาติมีเกณฑ์การรับยังไงบ้าง?',\n",
    "  'ถ้าสนใจจะเรียนวิศวะคอม/ เปิดรับเมื่อไหร่ ช่วงไหนบ้าง?',\n",
    "  'วิศวะคอม/ สามารถสมัครเข้าเรียนยังไงได้บ้าง มีรอบอะไรเปิดรับบ้าง?',\n",
    "  'แต่ละหลักสูตรมีเกณฑ์การรับพื้นฐานยังไงบ้าง?',\n",
    "  'ถ้าจะสมัครเข้าโครงการ Active Recruitment ใช้เอกสารอะไรบ้าง?',\n",
    "  'วิศวะคอม/ TCAS รอบ 1 มีโครงการไหนเปิดรับบ้าง?',\n",
    "  'การับสมัครเด็กเข้าเรียน มีทั้งหมดกี่รอบ? อะไรบ้าง?',\n",
    "  'สามารถติดต่อข่าวสารช่องทางการรับสมัครได้ที่ช่องทางไหนบ้าง? ',\n",
    "  'จะต้องใช้เอกสารอะไรบ้างในการสมัครเข้าศึกษา']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ฝึกงาน\n",
    "internship = ['ถ้าไม่ได้เป็นนักศึกษาชั้นปีที่ 3 สามารถฝึกงานได้หรือไม่？',\n",
    "  'หากไม่สามารถหาที่ฝึกงานในช่วงนี้ได้ จะต้องดรอปวิชาฝึกงานไหม',\n",
    "  'Work Integrate Leaning หรือ Wil จำเป็นที่ลงเลือกวิชาเลือกเสรีหรือไม่?',\n",
    "  'หากไม่่สามารถฝึกงานได้ต้องทำอย่างไร',\n",
    "  'ถ้าต้องการฝึกงานต้องทำอย่างไรบ้าง?',\n",
    "  'ฝึกงานจำเป็นต้องครบ40ชั่วโมงไหม？',\n",
    "  'Work Integrate Leaning หรือ Wil ทำตั้งแต่ช่วงเวลาไหนถึงไหน?',\n",
    "  'ถ้าต้องการทำ Work Integrate Leaning หรือ Wil ต้องทำอย่างไร?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#หลักสูตร\n",
    "curriculum = ['วิชา CPE332/Professional issuesมีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชาเลือกที่มีวิชาบังคับลงก่อน หลักสูตรปกติ?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 4 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 4 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชาเลือกที่มีวิชาบังคับลงก่อน หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ ?',\n",
    "  'วิชา CPE375/Interactive computingมีวิชาตัวต่อมั้ยครับ?',\n",
    "  'หน่วยกิตที่ต้องเก็บให้ครบก่อนจบหรือไม่?',\n",
    "  'วิศวะคอม/วิศวกรรมคอมพิวเตอหลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 3 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชา CPE224/Computer architectures มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติปี 1 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติปี 1 เทอม 1 \\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชาเลือกที่มีวิชาบังคับลงก่อน หลักสูตรนานาชาติ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ มีกี่หน่วยกิต? ',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ ปีที่1-2 เรียนอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติปี 2 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชา CPE212/Algorithm มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ  ปี 4 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอมหลักสูตรวิทยาศาตร์ข้อมูลสุขภาพมีอัตราค่าเรียนเท่าไหร่',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 3 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชาภาคบังคับที่มีวิชาต่อเนื่อง มีอะไรบ้าง หลักสูตรปกติ?',\n",
    "  'วิชา CPE314/Computer networksมีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรเรสิเดนทอล คอเลจ ปีที่ 1-2 เรียนอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ ปีที่ 3 เรียนอะไรบ้าง?',\n",
    "  'วิชา CPE327/Software engineering มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอมพิวเตอร์แต่ละหลักสูตรมีระยะเวลาในการศึกษากี่ปี?',\n",
    "  'วิชา CPE325/Big data มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชา CPE111/Data Structure มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ ปี 2 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 2 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชาเลือกเสรีต้องลงวิชานอกภาคเท่านั้นหรือไม่?',\n",
    "  'วิศวะคอมหลักสูตรปกติมีอัตราค่าเรียนเท่าไหร่',\n",
    "  'วิชา CPE326/Operating systems มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชา CPE121/Discrete มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ ปีที่ 4 เรียนอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ มีกี่หน่วยกิต?',\n",
    "  'วิชา CPE342/Java programmingมีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชาภาษาอังกฤษ LNG มีเกณท์การเรื่มเรียนอย่างไร หลักสูตรวิทยาศาสตรบัณฑิต\\nสาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ ?',\n",
    "  'วิชา CPE343/Object orientedมีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชา CPE100/Programming มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ มีกี่หน่วยกิต?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 1 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ ปี 3 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ ปีที่1-2 เรียนอะไรบ้าง?',\n",
    "  'วิชา CPE223/Digital มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติปี 4 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชา CPE101/Exploration มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรเรสิเดนทอล คอเลจ ปีที่ 3-4 เรียนอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 3 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชาภาษาอังกฤษ LNG มีเกณท์การเรื่มเรียนอย่างไร หลักสูตรปกติ ?',\n",
    "  'วิชาภาคบังคับที่มีตัวต่อเนื่องมีอะไรบ้าง หลักสูตรนานาชาติ?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ  ปี 3 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรวิทยาศาตร์ข้อมูลสุขภาพ ปีที่1-2 เรียนอะไรบ้าง?',\n",
    "  'วิชา CPE231/Database มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิชาภาคบังคับที่มีวิชาต่อเนื่อง  หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nมีอะไรบ้าง ?',\n",
    "  'วิชาภาษาอังกฤษ LNG มีเกณท์การเรื่มเรียนอย่างไร หลักสูตรนานาชาติ ?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ ปีที่ 3 เรียนอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ  ปี 2 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ ปี 1 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอมหลักสูตรปกติมีระยะเวลาในการศึกษากี่ปี?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 2 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชา CPE213/Data model วิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 1 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวะคอม/ มีทั้งหมดกี่หลักสูตร? มีหลักสูตรอะไรบ้าง?',\n",
    "  'วิศวะคอมหลักสูตรนานาชาติมีอัตราค่าเรียนเท่าไหร่',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 4 เทอม 1 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ ปีที่ 4 เรียนอะไรบ้าง?',\n",
    "  'วิชา CPE122/Circuits มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ  ปี 4 เทอม 2\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรนานาชาติ ปีที่ 3 เรียนอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติ ปี 3 เทอม 1\\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิชา CPE329/Business intelligence มีวิชาตัวต่อมั้ยครับ?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตรบัณฑิต สาขาวิชาวิทยาศาสตร์ข้อมูลสุขภาพ \\nปี 2 เทอม 2 ต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?',\n",
    "  'วิศวกรรมคอมพิวเตอร์หลักสูตรปกติ ปีที่ 4 เรียนอะไรบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรปกติ ปี 1 เทอม 1 \\nต้องลงเรียนกี่หน่วยกิต? เรียนวิชาอะไรบ้าง?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# คำถามทั่วไป\n",
    "faq = ['เวลาต้องการยื่นเอกสารต้องยื่นที่ไหน',\n",
    "  'วิศวะคอม/หลักสูตรเรสิเดนทอล คอลเลจจบแล้วได้ปริญญาอะไร?',\n",
    "  'ขั้นตอนและช่วงเวลาเปิดรับสมัครนักศึกษา?',\n",
    "  'หลักสูตรวิทยาศาสตร์ข้อมูลสุขภาพจบมาแล้วทำงานในสายใดบ้าง?',\n",
    "  'วิศวะคอม/หลักสูตรปกติจบแล้วได้ปริญญาอะไร?',\n",
    "  'เรียนจบต้องใช้คะแนนอังกฤษอะไรบ้าง ขั้นตํ่าเท่าไหร่??',\n",
    "  'หลักสูตรนานาชาติจบมาแล้วทำงานในสายใดบ้าง?',\n",
    "  'สามารถติดต่ออ.ได้ช่องทางไหนบ้าง?',\n",
    "  'สมัครหลักสูตรยังไง?',\n",
    "  'ขั้นตอนการรับสมัครโครงการทุนการศึกษา?',\n",
    "  'วิศวะคอม/เรียนเกี่ยวกับอะไร?',\n",
    "  '/วิศวะคอมพิวเตอร์ เรียนจบทำงานอะไร',\n",
    "  'การส่งคะแนนสอบภาษาอังกฤษเพื่อสำเร็จการศึกษา ส่งอย่างไร?',\n",
    "  'ใครเป็นหัวหน้าภาควิชาวิศวะคอม/?',\n",
    "  'มีที่ฝึกงานแนะนำไหม?',\n",
    "  'ติดต่อวิศวะคอม/ได้ทางช่องทางไหนได้บ้าง?',\n",
    "  'สามารถติดต่อได้ทางช่องทางไหนบ้าง ช่วงเวลากี่โมงถึงกี่โมง?',\n",
    "  'หลักสูตรเรสิเดรเทียล คอเจน์จบมาแล้วทำงานในสายใดบ้าง?',\n",
    "  'วิศวะคอม/แตกต่างจาก IT อย่างไร?',\n",
    "  'วิศวะคอม/หลักสูตรวิทยาศาสตร์ข้อมูลสุขภาพจบแล้วได้ปริญญาอะไร?',\n",
    "  'เกียรตินิยมอันดับ 2 อยู่ที่เท่าไหร่?',\n",
    "  'หลักสูตรวิิทยาศาสตร์ข้อมูลสุขภาพคืออะไร?',\n",
    "  'วิศวะคอม/จบไปทำงานอะไร?',\n",
    "  'อาจารย์ในภาควิชาวิศวะคอม/มีใครบ้าง? ',\n",
    "  'เกียรตินิยมอันดับ 1 อยู่ที่เท่าไหร่?',\n",
    "  'หลักสูตรปกติจบมาแล้วทำงานในสายใดบ้าง?',\n",
    "  'วิศวะคอม/แล้วได้ปริญญาอะไร?',\n",
    "  'วิศวะคอม/หลักสูตรนานาชาติจบแล้วได้ปริญญาอะไร?',\n",
    "  'วิศวะคอม/อยู่ที่ไหน?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทุนการศึกษา\n",
    "scholarship = ['สามารถขอทุนอะไรบ้าง?',\n",
    "  'ทุนเพชรพระจอมเกล้าภาควิชารับกี่คน？',\n",
    "  'ทุนของภาควิชามีอะไรบ้าง？',\n",
    "  'การสมัครกู้ยืมเรียน ทำอย่างไร?',\n",
    "  'ถ้าอยากไปเรียนต่อต่างและขอทุนต่างประเมศต้องทำอย่างไรบ้าง？',\n",
    "  'มีเงินไม่พอจ่าย ทำอะไรได้บ้าง?',\n",
    "  'ทุนจ้างงานคืออะไร？',\n",
    "  'ปัจจุบันมีทุนอะไรเปิดรับบ้าง?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollmentObj = {'enrollment':enrollment}\n",
    "admissionObj = {'admission':admission}\n",
    "internshipObj = {'internship':internship}\n",
    "curriculumObj = {'curriculum':curriculum}\n",
    "faqObj = {'faq':faq}\n",
    "scholarshipObj = {'scholarship':scholarship}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollmentDF = pd.DataFrame(data=enrollmentObj)\n",
    "admissionDF = pd.DataFrame(data=admissionObj)\n",
    "internshipDF = pd.DataFrame(data=internshipObj)\n",
    "curriculumDF = pd.DataFrame(data=curriculumObj)\n",
    "faqDF = pd.DataFrame(data=faqObj)\n",
    "scholarshipDF = pd.DataFrame(data=scholarshipObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "beforeTok = {}\n",
    "beforeTok['ลงทะเบียนเรียน'] = enrollmentDF\n",
    "beforeTok['การรับเข้านักศึกษา'] = admissionDF\n",
    "beforeTok['ฝึกงาน'] = internshipDF\n",
    "beforeTok['หลักสูตร'] = curriculumDF\n",
    "beforeTok['คำถามทั่วไป'] = faqDF\n",
    "beforeTok['ทุนการศึกษา'] = scholarshipDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'สามารถขอทุนอะไรบ้าง?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beforeTok['ทุนการศึกษา'].loc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_enrollment =enrollmentDF.enrollment.map(tokenize_text_list)\n",
    "tokenized_admission =admissionDF.admission.map(tokenize_text_list)\n",
    "tokenized_internship =internshipDF.internship.map(tokenize_text_list)\n",
    "tokenized_curriculum =curriculumDF.curriculum.map(tokenize_text_list)\n",
    "tokenized_faq =faqDF.faq.map(tokenize_text_list)\n",
    "tokenized_scholarship =scholarshipDF.scholarship.map(tokenize_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = {}\n",
    "tokenized['ลงทะเบียนเรียน'] = tokenized_enrollment\n",
    "tokenized['การรับเข้านักศึกษา'] = tokenized_admission\n",
    "tokenized['ฝึกงาน'] = tokenized_internship\n",
    "tokenized['หลักสูตร'] = tokenized_curriculum\n",
    "tokenized['คำถามทั่วไป'] = tokenized_faq\n",
    "tokenized['ทุนการศึกษา'] = tokenized_scholarship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_len = {}\n",
    "tokenized_len['ลงทะเบียนเรียน'] = len(tokenized['ลงทะเบียนเรียน'])\n",
    "tokenized_len['การรับเข้านักศึกษา'] = len(tokenized['การรับเข้านักศึกษา'])\n",
    "tokenized_len['ฝึกงาน'] = len(tokenized['ฝึกงาน'])\n",
    "tokenized_len['หลักสูตร'] = len(tokenized['หลักสูตร'])\n",
    "tokenized_len['คำถามทั่วไป'] = len(tokenized['คำถามทั่วไป'])\n",
    "tokenized_len['ทุนการศึกษา'] = len(tokenized['ทุนการศึกษา'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_len['ลงทะเบียนเรียน']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9rvOcqWW5sY"
   },
   "source": [
    "# time total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "executionInfo": {
     "elapsed": 1243,
     "status": "ok",
     "timestamp": 1620718089261,
     "user": {
      "displayName": "Natkanok Poksappaiboon",
      "photoUrl": "",
      "userId": "02284855325556491333"
     },
     "user_tz": -420
    },
    "id": "BjaHxfYqRSKQ",
    "outputId": "9a22dc57-b706-458c-c6ff-ea6fb0e664dd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-e36182fd4f37>:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if w not in wv_model:\n",
      "<ipython-input-15-e36182fd4f37>:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9963009]\n",
      "(array([62], dtype=int64), array([0], dtype=int64))\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputQuestion = \"วิศวคอมมีหลักสูตรอะไรบ้าง\"\n",
    "# print('input: ' + inputQuestion)\n",
    "\n",
    "#category model\n",
    "inputQuestion= cleansing(inputQuestion)\n",
    "tokenized_input_2 = inputQuestion\n",
    "tokenized_text = deepcut.tokenize(tokenized_input_2)\n",
    "x = text_to_bow([tokenized_text], vocabulary_)\n",
    "x_tfidf = transformer.transform(x)\n",
    "x_svd = svd_model.transform(x_tfidf)\n",
    "pred = [model.predict_proba(x_svd.reshape(-1, 1).T).ravel()[1] for model in logist_models]\n",
    "\n",
    "# print(list(zip(tag, pred)))\n",
    "predict_category = max(list(zip(tag, pred)))\n",
    "max_value = 0\n",
    "max_category = ''\n",
    "pred_results = list(zip(tag, pred))\n",
    "\n",
    "for pred_result in pred_results:\n",
    "    # print(pred_result)\n",
    "    if pred_result[1] > max_value:\n",
    "        max_value = pred_result[1]\n",
    "        max_category = pred_result[0]\n",
    "# print(max_category, max_value)\n",
    "# end of category model\n",
    "\n",
    "\n",
    "# print(tokenized[max_category])\n",
    "\n",
    "\n",
    "# prediction\n",
    "tokenized_category = tokenized[max_category]\n",
    "# print(tokenized_category)\n",
    "max_word = 19219\n",
    "max_seq_length = 2704\n",
    "q_category= []\n",
    "for sentence in tokenized_category:\n",
    "    q_category.append(sentence)\n",
    "q_category = word_index(q_category)\n",
    "all_Question_categorylen = len(q_category)\n",
    "# all_Question_categorylen\n",
    "\n",
    "tokenized_dup_input_2= duplicate([tokenized_input_2],all_Question_categorylen)\n",
    "# print(tokenized_dup_input_2)\n",
    "\n",
    "q_user = word_index(tokenized_dup_input_2)\n",
    "# Split to dicts\n",
    "M_input = {'left': q_category, 'right': q_user}\n",
    "# Zero padding\n",
    "for model_input, side in itertools.product([M_input], ['left', 'right']):\n",
    "    model_input[side] = pad_sequences(model_input[side], maxlen=max_seq_length)\n",
    "\n",
    "# Make sure everything is ok\n",
    "assert M_input['left'].shape == M_input['right'].shape\n",
    "play_predict = malstm.predict(x=[M_input['left'], M_input['right']])\n",
    "\n",
    "max_question_percentage = max(play_predict)\n",
    "print(max_question_percentage)\n",
    "question_index = np.where(play_predict == max_question_percentage)\n",
    "print(question_index)\n",
    "predictedQuestion = beforeTok[max_category].loc[question_index[0][0]]\n",
    "predictedQuestion = predictedQuestion[0]\n",
    "\n",
    "value = {\n",
    "    \"category\": max_category,\n",
    "    \"accuracy\": \"%lf\" % max_value,\n",
    "    \"predictedQuestion\": str(predictedQuestion),\n",
    "    \"similarity\": \"%lf\" % max_question_percentage\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: วิศวคอมมีหลักสูตรอะไรบ้าง\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputQuestion = \"วิศวคอมมีหลักสูตรอะไรบ้าง\"\n",
    "print('input: ' + inputQuestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#category model\n",
    "tokenized_input_2= cleansing(inputQuestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_text = deepcut.tokenize(tokenized_input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 997 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = text_to_bow([tokenized_text], vocabulary_)\n",
    "x_tfidf = transformer.transform(x)\n",
    "x_svd = svd_model.transform(x_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 997 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = [model.predict_proba(x_svd.reshape(-1, 1).T).ravel()[1] for model in logist_models]\n",
    "# print(list(zip(tag, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predict_category = max(list(zip(tag, pred)))\n",
    "max_value = 0\n",
    "max_category = ''\n",
    "pred_results = list(zip(tag, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "หลักสูตร 0.4197960318923689\n",
      "Wall time: 996 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for pred_result in pred_results:\n",
    "    # print(pred_result)\n",
    "    if pred_result[1] > max_value:\n",
    "        max_value = pred_result[1]\n",
    "        max_category = pred_result[0]\n",
    "print(max_category, max_value)\n",
    "# end of category model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prediction\n",
    "tokenized_category = tokenized[max_category]\n",
    "# print(tokenized_category)\n",
    "max_word = 19219\n",
    "max_seq_length = 2704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.99 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-e36182fd4f37>:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if w not in wv_model:\n",
      "<ipython-input-15-e36182fd4f37>:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(dataset)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q_category= []\n",
    "for sentence in tokenized_category:\n",
    "    q_category.append(sentence)\n",
    "q_category = word_index(q_category)\n",
    "all_Question_categorylen = len(q_category)\n",
    "# all_Question_categorylen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 67.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_input_2 = deepcut.tokenize(inputQuestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_dup_input_2= duplicate([tokenized_input_2],all_Question_categorylen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.99 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-e36182fd4f37>:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if w not in wv_model:\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q_user = word_index(tokenized_dup_input_2)\n",
    "# Split to dicts\n",
    "M_input = {'left': q_category, 'right': q_user}\n",
    "# Zero padding\n",
    "for model_input, side in itertools.product([M_input], ['left', 'right']):\n",
    "    model_input[side] = pad_sequences(model_input[side], maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make sure everything is ok\n",
    "assert M_input['left'].shape == M_input['right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "play_predict = malstm.predict(x=[M_input['left'],  M_input['right']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9963009]\n",
      "(array([62], dtype=int64), array([0], dtype=int64))\n",
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_question_percentage = max(play_predict)\n",
    "print(max_question_percentage)\n",
    "question_index = np.where(play_predict == max_question_percentage)\n",
    "print(question_index)\n",
    "predictedQuestion = beforeTok[max_category].loc[question_index[0][0]]\n",
    "predictedQuestion = predictedQuestion[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = {\n",
    "    \"category\": max_category,\n",
    "    \"accuracy\": \"%lf\" % max_value,\n",
    "    \"predictedQuestion\": str(predictedQuestion),\n",
    "    \"similarity\": \"%lf\" % max_question_percentage\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Siamese_malstm_play.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
